<!DOCTYPE html>


<html lang="zh-CN">


<head>
  <meta name="baidu-site-verification" content="codeva-NSg7ynviLa" />
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    方差组分估计常用方法介绍 |  
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/images/mojie.jpg" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">
  
<link rel="stylesheet" href="/css/custom.css">

  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  

<link rel="alternate" href="/atom.xml" title="null" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-方差组分估计常用方法介绍"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  方差组分估计常用方法介绍
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/posts/d7d9056/" class="article-date">
  <time datetime="2022-04-30T01:51:56.000Z" itemprop="datePublished">2022-04-30</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/">理论学习</a> / <a class="article-category-link" href="/categories/%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/">线性模型</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">2.9k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">10 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>方差组分估计应该是遗传评估中最难的一部分，资料也不是很好找，尽量整理了一下。</p>
<span id="more"></span>
<h1>ML</h1>
<p>在最大似然方法中，我们需要新增分布假设，一般我们都采用<strong>正态假设</strong>，因此模型假设为 (这里假设所有随机效应的协方差矩阵均为对角矩阵)</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7By%7D%20%5Ctext%20%7B%20is%20%7D%20N_%7Bn%7D%28%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%2C%20%5Cmathbf%7BV%7D%29%2C%20%5Cquad%20%5Ctext%20%7B%20where%20%7D%20%5Cquad%20%5Cmathbf%7BV%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%2B%5Csigma%5E%7B2%7D%20%5Cmathbf%7BI%7D_%7Bn%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=n%20%5Ctimes%20p" style="display:inline-block;margin: 0;"/> 并且秩为 $ r \leq p$ 的矩阵。<img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cmathbf%7BV%7D%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=n%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/> 的<strong>正定</strong>矩阵。为了方便书写，我们记 <img src="https://math.now.sh?inline=%5Csigma_%7B0%7D%5E%7B2%7D%3D%5Csigma%5E%7B2%7D" style="display:inline-block;margin: 0;"/> ， <img src="https://math.now.sh?inline=%5Cmathbf%7BZ%7D_%7B0%7D%3D%5Cmathbf%7BI%7D_%7Bn%7D" style="display:inline-block;margin: 0;"/> ，因此协方差矩阵变成 (假设随机向量之间互不相关)</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BV%7D%3D%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%0A" /></p><p>随机向量 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 的联合分布密度函数，即似然函数为</p>
<p style=""><img src="https://math.now.sh?from=L%28%5Cmathbf%7By%7D%29%3D%5Cfrac%7B1%7D%7B(2%20%5Cpi)%5E%7Bn%20%2F%202%7D%7C%5Cmathbf%7BV%7D%7C%5E%7B1%20%2F%202%7D%7D%20%5Cexp%20%5Cleft%5C%7B-0.5(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%5Cright%5C%7D%0A" /></p><p>其对数为</p>
<p style=""><img src="https://math.now.sh?from=L%3D-0.5%20n%20%5Ctimes%20%5Cln%20%282%20%5Cpi%29-0.5%20%5Cln%20%7C%5Cmathbf%7BV%7D%7C-0.5(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%0A" /></p><p>对他求未知参数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5E%7B%5Cprime%7D%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Blllll%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%5Cprime%7D%20%26%20%5Csigma_%7B0%7D%5E%7B2%7D%20%26%20%5Csigma_%7B1%7D%5E%7B2%7D%20%26%20%5Ccdots%20%26%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cend%7Barray%7D%5Cright%5D'" style="display:inline-block;margin: 0;"/> 的偏导数如下（证明略）</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Cbeta%7D%7D%3D-%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D-%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright%29%20%5C%5C%0A%26%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cright)%2B%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%20%5C%5C%0A%26%5Cleft(%5Cbecause%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cln%20%7C%5Cmathbf%7BV%7D%7C%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cright)%2C%20%5Cquad%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%3D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%5Cright)%0A%5Cend%7Baligned%7D%0A" /></p><p>令上面两式为0，我们设 $ \frac{\partial \mathbf{V}}{\partial \sigma_{i}^{2}}  = \mathbf{V}_{i}$ ，因此我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%20%26%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%20%5C%5C%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%20%26%3D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%0A%5Cend%7Baligned%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> ，因为下式成立</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%26%3D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%5Cright)%20%5Cmathbf%7By%7D%20%5C%5C%0A%26%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%5Cleft(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright)%20%5C%5C%0A%26%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%0A%5Cend%7Baligned%7D%0A" /></p><p>因为</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5Cright)%3D%5Csum_%7Bj%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%20%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright)%0A" /></p><p>故有 ML 的估计方程为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Csum_%7Bj%7D%20%5Cleft%5C%7B%5Coperatorname%7Btr%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%3D%5Cleft%5C%7B%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%5Cright%5C%7D%20%5C%5C%0A%26i%2C%20j%3D0%2C1%2C%20%5Ccdots%2C%20m%0A%5Cend%7Baligned%7D%0A" /></p><p>根据此式子，我们显然找不到闭式解，还需要采用迭代的方式求解。</p>
<p>似然法的一个缺点式，当数据量比较小时，其估计值时有偏的。而且随着固定效应水平数目的增加和随机效应水平数目的减少，其偏差会愈加严重。</p>
<h1>REML</h1>
<p><strong>限制性最大似然</strong> (<em>restricted (residual) maximum likelihood</em>, REML) ，由  Patterson 和 Thompson 在 1971 年提出。我们强调 REML 方法的原因是在标准的线性模型中，样本方差 <img src="https://math.now.sh?inline=s%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 也是 REML 的估计值。同时，REML 是一种一般的方法，比如 REML 在不平衡数据中也可以使用。在某些平衡数据中，REML 可能有解析解 (闭式解)。REML 同时是<strong>最佳二次无偏估计值</strong>。</p>
<p>REML 的思想是对数据 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'y%7D" style="display:inline-block;margin: 0;"/> 进行最大似然估计，而不是 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> ，这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是我们人为挑选的，以使得  <img src="https://math.now.sh?inline=%5Cmathbf%7BK'y%7D" style="display:inline-block;margin: 0;"/> 的分布只包含方差组分，而不包含 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cbeta%7D" style="display:inline-block;margin: 0;"/> 。为了实现这一点，矩阵 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 需要满足 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20X%7D%3D%5Cmathbf%7BO%7D" style="display:inline-block;margin: 0;"/> ，因此 <img src="https://math.now.sh?inline=E%28%5Cmathbf%7BK'%20y%7D%29%3D%5Cmathbf%7BK'%20X%7D%5Cboldsymbol%7B%5Cbeta%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 。为了方便，我们同时要求  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是一个<strong>满秩</strong>矩阵。我们同时要求  <img src="https://math.now.sh?inline=%5Cmathbf%7BK'y%7D" style="display:inline-block;margin: 0;"/>  尽可能包含最多的关于方程组分的信息，因此  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 必须有最大的行数。</p>
<p><strong>定理</strong>：  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是一个满秩矩阵，满足 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20X%7D%3D%5Cmathbf%7BO%7D" style="display:inline-block;margin: 0;"/> ，但是同时拥有最大的行数，因此它是一个 <img src="https://math.now.sh?inline=%28n-r%29%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/> 的矩阵 (<img src="https://math.now.sh?inline=r" style="display:inline-block;margin: 0;"/> 为 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的秩)。进一步地说，<img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的形式必须为 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7BC%7D%28%5Cmathbf%7BI%7D-%5Cmathbf%7BH%7D%29%3D%5Cmathbf%7BC%7D%5Cleft%5B%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%5Cright%5D" style="display:inline-block;margin: 0;"/> ，这里  <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=%28n-r%29%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/>  的满秩矩阵。</p>
<p><strong>证明</strong>：<img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 的行 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 满足等式 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，转置得到 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7Bk%7D_%7Bi%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> （注意这里出现了符号重叠问题，这里的 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 行元素组成的列向量）。根据定理， <strong>如果线性方程组 <img src="https://math.now.sh?inline=Ax%20%3D%20c" style="display:inline-block;margin: 0;"/> 是相容的</strong>，那么所有可能的解为  <img src="https://math.now.sh?inline=%5Cmathbf%7Bx%7D%3D%5Cmathbf%7BA%7D%5E%7B-%7D%20%5Cmathbf%7Bc%7D%2B%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BA%7D%5E%7B-%7D%20%5Cmathbf%7BA%7D%5Cright%29%20%5Cmathbf%7Bh%7D" style="display:inline-block;margin: 0;"/>  ，这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 是某个特定的广义逆， <img src="https://math.now.sh?inline=h" style="display:inline-block;margin: 0;"/> 为所有可能的值组成的向量。因此，这里的方程组的解为 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%3D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5E%7B-'%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%5Cright%29%20%5Cmathbf%7Bc%7D" style="display:inline-block;margin: 0;"/> （书中有笔误，书里是 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%3D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5E%7B-%7D%20%5Cmathbf%7BX%7D%5Cright%29%20%5Cmathbf%7Bc%7D" style="display:inline-block;margin: 0;"/> ，这里又有符号重叠问题，这里的 <img src="https://math.now.sh?inline=%5Cmathbf%7Bc%7D" style="display:inline-block;margin: 0;"/> 就是上面定理中的 <img src="https://math.now.sh?inline=%5Cmathbf%7Bh%7D" style="display:inline-block;margin: 0;"/> ，为所有可能的 <img src="https://math.now.sh?inline=n%20%5Ctimes%201" style="display:inline-block;margin: 0;"/> 的向量） ，因此  $\mathbf{k}_{i}^{\prime}=\mathbf{c}^{\prime} \left(\mathbf{I}-\mathbf{X}\mathbf{X}^{-}\right) $ ，也就是说 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 的行 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 的行的所有可能的线性组合。</p>
<p>我们知道  <img src="https://math.now.sh?inline=%5Coperatorname%7Brank%7D%5Cleft%28%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29%3D%5Coperatorname%7Brank%7D(%5Cmathbf%7BX%7D)%3Dr" style="display:inline-block;margin: 0;"/> ，并且 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29%5E%7B2%7D%20%3D%20%5Cmathbf%7BI%7D-2%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B-%7D%2B%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B-%7D%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/>  ，因此 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 是一个<strong>幂等</strong>矩阵，因此 <img src="https://math.now.sh?inline=%5Coperatorname%7Brank%7D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright)%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright)%3Dn-r" style="display:inline-block;margin: 0;"/> ，因此 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 的行的张成空间的维度为 <img src="https://math.now.sh?inline=n-r" style="display:inline-block;margin: 0;"/> ，因此最多有  <img src="https://math.now.sh?inline=n-r" style="display:inline-block;margin: 0;"/>  个线性无关的向量 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，也就是说 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的行数最大为 <img src="https://math.now.sh?inline=n-r" style="display:inline-block;margin: 0;"/> 。</p>
<p>因为   $\mathbf{k}_{i}^{\prime}=\mathbf{c}^{\prime} \left(\mathbf{I}-\mathbf{X}\mathbf{X}^{-}\right) $  ，那么一定存在一个  <img src="https://math.now.sh?inline=%28n-r%29%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/>  的满秩矩阵   <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D" style="display:inline-block;margin: 0;"/>  ，使得  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵可以表示为 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7BC%7D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29" style="display:inline-block;margin: 0;"/> ，其中  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的每一行均是  <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 的行的线性组合，并且由于 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵满秩， 因此选择 <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D" style="display:inline-block;margin: 0;"/> 矩阵的标准是必须使得  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的行之间线性无关。根据广义逆的性质，我们知道 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的一个广义逆，因此我们可以这里的 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 可以选择为  <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，因此此时  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵可以表示为 <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D%28%5Cmathbf%7BI%7D-%5Cmathbf%7BH%7D%29%3D%5Cmathbf%7BC%7D%5Cleft%5B%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%5Cright%5D" style="display:inline-block;margin: 0;"/> 。</p>
<p>满足要求的  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵有无数个，但是这不影响我们使用。同时我们注意到校正固定效应的残差为 $\hat{\boldsymbol{\varepsilon}} = (\mathbf{I}-\mathbf{H}) \mathbf{y} $ ，因此</p>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D%3D%5Cmathbf%7BC%7D%28%5Cmathbf%7BI%7D-%5Cmathbf%7BH%7D%29%20%5Cmathbf%7By%7D%20%3D%20%5Cmathbf%7BC%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cvarepsilon%7D%7D" style="display:inline-block;margin: 0;"/> 的每个元素都是所有残差的线性组合，这也是 <em>residual maximum likelihood</em> 这个名称的由来。</p>
<p>而 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D" style="display:inline-block;margin: 0;"/> 的分布见下面的定理。</p>
<p><strong>定理</strong>：在混合线性模型中，假设 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D%20%5Csim%20N_%7Bn%7D%28%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%2C%20%5Cmathbf%7BV%7D%29" style="display:inline-block;margin: 0;"/> ，其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%3D%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，那么</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BK'%20y%7D%20%5Csim%20%20N_%7Bn-r%7D%5Cleft%28%5Cmathbf%7B0%7D%2C%20%5Cmathbf%7BK'%20%5Cmathbf%7BV%7D%7D%20%5Cmathbf%7BK%7D%5Cright%29%0A" /></p><p>证明很简单，因为  <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 满足正态，所以 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D" style="display:inline-block;margin: 0;"/> 也满足正态，同时根据  <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20X%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 易得 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D" style="display:inline-block;margin: 0;"/> 的均值为 <img src="https://math.now.sh?inline=%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> , 其方差为 $ \mathbf{K^{\prime} \mathbf{V}} \mathbf{K}$ ，得证。</p>
<p>因此  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D" style="display:inline-block;margin: 0;"/> 的分布只与 <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个方差组分有关。为了估计方差组分，REML 的下一步是针对这些方差组分最大化  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D" style="display:inline-block;margin: 0;"/> 的似然值。</p>
<p>对似然函数求偏导，使之为零，我们得到下面的定理。</p>
<p><strong>定理</strong>：在上面的模型中， <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个方差组分 <img src="https://math.now.sh?inline=%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 的估计值满足下面的方程组，其中 <img src="https://math.now.sh?inline=i%3D0%2C%20%5Cldots%2C%20m" style="display:inline-block;margin: 0;"/></p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%5B%5Cmathbf%7BK%7D%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%5D%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D%0A" /></p><p><strong>证明</strong>：因为 <img src="https://math.now.sh?inline=E%28%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%29%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，<img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D" style="display:inline-block;margin: 0;"/> 的对数似然值为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cln%20L%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29%3D%26%20%5Cfrac%7Bn-r%7D%7B2%7D%20%5Cln%20(2%20%5Cpi)-%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%5Cleft%7C%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright%7C-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%20%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%20%5C%5C%0A%3D%26%20%5Cfrac%7Bn-r%7D%7B2%7D%20%5Cln%20(2%20%5Cpi)-%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%5Cleft%7C%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cleft(%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright)%20%5Cmathbf%7BK%7D%20%5Cright%7C%20%5C%5C%0A%26-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft%5B%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cleft(%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright)%20%5Cmathbf%7BK%7D%5Cright%5D%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>根据矩阵求导的性质，假设 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=n%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/> 的<strong>非奇异矩阵</strong>，其元素 <img src="https://math.now.sh?inline=a_%7Bij%7D" style="display:inline-block;margin: 0;"/> 是关于标量 <img src="https://math.now.sh?inline=x" style="display:inline-block;margin: 0;"/> 的函数。我们定义  <img src="https://math.now.sh?inline=%5Cpartial%20%5Cmathbf%7BA%7D%20%2F%20%5Cpartial%20x" style="display:inline-block;margin: 0;"/> 是一个 $n \times n $ 的矩阵，其元素为 <img src="https://math.now.sh?inline=%5Cpartial%20a_%7Bi%20j%7D%20%2F%20%5Cpartial%20x" style="display:inline-block;margin: 0;"/> 。那么存在</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%5E%7B-1%7D%7D%7B%5Cpartial%20x%7D%3D-%5Cmathbf%7BA%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%7D%7B%5Cpartial%20x%7D%20%5Cmathbf%7BA%7D%5E%7B-1%7D%0A" /></p><p>和</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20%5Clog%20%7C%5Cmathbf%7BA%7D%7C%7D%7B%5Cpartial%20x%7D%3D%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BA%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%7D%7B%5Cpartial%20x%7D%5Cright%29%0A" /></p><p>利用这两条性质，我们求 <img src="https://math.now.sh?inline=%5Cln%20L%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29" style="display:inline-block;margin: 0;"/> 对每一个 <img src="https://math.now.sh?inline=%5Csigma_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 的偏导数，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cln%20L%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29%3D%26-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cleft(%5Cmathbf%7BK%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%5Cleft%5B%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cleft(%5Cmathbf%7BK%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%7D%20%5Cmathbf%7BK%7D%5Cright)%5Cright%5D%5Cright)%20%5C%5C%0A%26%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%5Cleft%5B%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5Cright%5D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%20%5C%5C%0A%3D%26-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft%5B%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cright%5D%20%5C%5C%0A%26%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D%20%5C%5C%0A%3D%26-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft%5B%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%5D%20%5C%5C%0A%26%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>将这个式子设为0，得到上面的结果。</p>
<p>证毕。</p>
<p>有一点很有意思，根据二次型的期望公式 <img src="https://math.now.sh?inline=E%5Cleft%28%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%20y%7D%5Cright%29%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BA%7D%20%5Cmathbf%7BV%7D)%2B%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D%20%5Cboldsymbol%7B%5Cmu%7D" style="display:inline-block;margin: 0;"/> ，上面式子的右手项的期望 (这里设期望公式里的 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 是  $\mathbf{K^{\prime}y} $  ，<img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D%20%3D%20%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%20%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> )  正好是左手项。</p>
<p>SEARLE (1979) 证明 (这篇文献没找到)</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BK%7D%20%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%20K%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7BP%7D%0A" /></p><p>证明如下：</p>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%3D%5Cmathbf%7BK%7D%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/>  和 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%3D%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是对称幂等矩阵，对称证明略，幂等证明如下，$(\mathbf{K K}^{+})^{2} = \mathbf{K K}^{+} \mathbf{K K}^{+}  = \mathbf{K K}^{+} $ 。我们已知 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，因此 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 并且 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%20%5Cmathbf%7BK%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 。因此</p>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BT%7D%3D%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D" style="display:inline-block;margin: 0;"/> 是一个对称幂等矩阵，幂等证明如下（其实直接根据对称幂等矩阵的性质即可证明，如果 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 对称幂等，那么 <img src="https://math.now.sh?inline=%5Cmathbf%7BI-A%7D" style="display:inline-block;margin: 0;"/> 对称幂等 ）：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Cleft%28%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5Cright%29%5Cleft(%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5Cright)%20%5C%5C%0A%26%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%2B%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%2B%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20-%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%2B%20%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%20%2B%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5C%5C%0A%26%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%2B%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%20-%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%20%20%2B%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5C%5C%0A%26%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>因此</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BT%20T%7D%5E%7B%5Cprime%7D%5Cright%29%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BT%7D%5E%7B2%7D%5Cright)%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BT%7D)%20%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%5Cright)-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%5Cright)%20%5C%5C%0A%26%3DN-r_%7B%5Cmathbf%7BX%7D%7D-r_%7B%5Cmathbf%7BK%7D%7D%20%5C%5C%0A%26%3DN-r_%7B%5Cmathbf%7BX%7D%7D-%5Cleft(N-r_%7B%5Cmathbf%7BX%7D%7D%5Cright)%20%5C%5C%0A%26%3D0%0A%5Cend%7Baligned%7D%0A" /></p><p>根据幂等矩阵的性质，我们知道幂等矩阵的秩等于迹，因此  <img src="https://math.now.sh?inline=%5Coperatorname%7Brank%7D%28%5Cmathbf%7BT%7D%29%20%3D%200" style="display:inline-block;margin: 0;"/> ，说明 <img src="https://math.now.sh?inline=%5Cmathbf%7BT%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> （只有零矩阵的秩为 0）。因此，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%3D%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%0A" /></p><p>因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D" style="display:inline-block;margin: 0;"/> 是一个正定矩阵，因此总是存在 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B1%2F2%7D" style="display:inline-block;margin: 0;"/> 矩阵使得 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%20%3D%20%28%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%29%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 。那么由于  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/>  ，那么我们知道 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，之前适应 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的结果均适用于 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D" style="display:inline-block;margin: 0;"/> 和 $ \mathbf{V}^{-1/2} \mathbf{X}$ 。我们替换 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%3D%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D" style="display:inline-block;margin: 0;"/> 中的MP逆矩阵，我们得到 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%3D%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 。将  <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D" style="display:inline-block;margin: 0;"/> 和 $ \mathbf{V}^{-1/2} \mathbf{X}$  带入得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BI%7D-%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%3D%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%0A" /></p><p>因此 （注意下面的 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 是 MP 逆 ）</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BP%7D%3D%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%3D%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%0A" /></p><p>得证。</p>
<p>其中 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/>  ，将该式带入，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%0A" /></p><p>注意最大似然法的估计公式为 $\operatorname{tr}\left(\hat{\mathbf{V}}^{-1} \mathbf{V}<em>{i}\right)<br>
=\mathbf{y}^{\prime} \hat{\mathbf{P}} \mathbf{V}</em>{i} \hat{\mathbf{P}} {\mathbf{y}} $ ，因此 REML 方法就是将左手项的 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 替换为 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Chat%7BP%7D%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BPVP%7D%20%26%3D%20%5Cleft%28%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cright)%20%5Cmathbf%7BV%7D%20%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cright)%20%5C%5C%0A%0A%26%3D%20%5Cleft(%5Cmathbf%7BI%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%20%5Cright)%20%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cright)%20%5C%5C%0A%0A%26%3D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20-%20%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%2B%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5C%5C%0A%0A%26%3D%20%5Cmathbf%7BP%7D%20%5Cquad%20%5Cbecause%20%20%5Ctext%7B%E8%AE%BE%7D%20%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Ctext%7B%E6%98%AF%E8%87%AA%E5%8F%8D%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>因此，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright)%20%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Cmathbf%7BP%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5Cright)%20%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%5Cright)%20%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%20%5C%5C%0A%26%3D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%5Cright)%20%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>因而，对于 <img src="https://math.now.sh?inline=i%2Cj%20%3D%200%2C1%2C%5Ccdots%2C%20m" style="display:inline-block;margin: 0;"/> ，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%5Cleft%5C%7B%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%7B%5Cmathbf%7BV%7D_%7Bj%7D%7D%5Cright%29%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%3D%5Cleft%5C%7B%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%5Cright%5C%7D%0A" /></p><p>这就是 REML 的估计方程，它也必须通过迭代求解。</p>
<p>根据这个定理，我们可以得到 <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个方程，而我们总共有 <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个未知数。在某些情况下，这些方程组可以进一步简化从而得到闭式解。但是在大多数情况下，这些方程组是无法直接求解的。</p>
<p>我们一般会用一些迭代的方法来进行估计 (Rao 1997 pp. 104 – 105, McCulloch and Searle 2001, pp. 265 – 269)。我们注意到上面定理中的 <img src="https://math.now.sh?inline=m%20%2B1" style="display:inline-block;margin: 0;"/> 个方程组成的方程组可以写为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BM%7D%20%5Cboldsymbol%7B%5Csigma%7D%3D%5Cmathbf%7Bq%7D%0A" /></p><p>这里 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D%3D%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Csigma_%7B1%7D%5E%7B2%7D%2C%20%5Ccdots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D" style="display:inline-block;margin: 0;"/> 是一个<strong>非奇异</strong>的  <img src="https://math.now.sh?inline=%28m%2B1%29%20%5Ctimes(m%2B1)" style="display:inline-block;margin: 0;"/> 的矩阵，其中的元素 <img src="https://math.now.sh?inline=M_%7Bij%7D%3D%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%7B%5Cmathbf%7BV%7D_%7Bj%7D%7D%5Cright%29" style="display:inline-block;margin: 0;"/> ，然后 <img src="https://math.now.sh?inline=%5Cmathbf%7Bq%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=%28m%2B1%29%20%5Ctimes%201" style="display:inline-block;margin: 0;"/> 的向量，其中的元素  <img src="https://math.now.sh?inline=q_%7Bi%7D%20%3D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>我们注意到 <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D%20%5Cboldsymbol%7B%5Csigma%7D%3D%5Cmathbf%7Bq%7D" style="display:inline-block;margin: 0;"/> 这个式子貌似更加复杂，因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D" style="display:inline-block;margin: 0;"/>  和 <img src="https://math.now.sh?inline=%5Cmathbf%7Bq%7D" style="display:inline-block;margin: 0;"/> 中都含有未知数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D" style="display:inline-block;margin: 0;"/> 。然而，这个方程组对于我们从一个初始值 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D_%7B%281%29%7D" style="display:inline-block;margin: 0;"/> 逐步迭代来估计的方式而言很有用。我们在第 <img src="https://math.now.sh?inline=t" style="display:inline-block;margin: 0;"/> 步可以用 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D_%7B%28t%29%7D" style="display:inline-block;margin: 0;"/> 来计算  <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D_%7B%28t%29%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7Bq%7D_%7B%28t%29%7D" style="display:inline-block;margin: 0;"/> ，那么 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D_%7B%28t%2B1%29%7D%3D%5Cmathbf%7BM%7D_%7B(t)%7D%5E%7B-1%7D%20%5Cmathbf%7Bq%7D_%7B(t)%7D" style="display:inline-block;margin: 0;"/> ，然后一直迭代直到收敛。</p>
<h2 id="EM-算法">EM 算法</h2>
<p>对于公式 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> ，我们在等式两边同乘以 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D%5E%7B2%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> ，并求总和，得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Csum%20%5Cmathbf%7B%5Chat%7BV%7D%7D_%7Bi%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%5Cright%29%20%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Csum%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%20%5C%5C%0A%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%20%5Cmathbf%7B%5Chat%7BV%7D%7D%5Cright)%20%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%20%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>我们先看左手项 (下面的 <img src="https://math.now.sh?inline=N" style="display:inline-block;margin: 0;"/> 是表型数目，<img src="https://math.now.sh?inline=r" style="display:inline-block;margin: 0;"/> 为 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的秩)</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%29%20%26%3D%5Coperatorname%7Btr%7D%5Cleft%5B%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%5Cright)%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5Cright%5D%20%5C%5C%0A%0A%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft%5B%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cright%5D%20%5C%5C%0A%0A%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft%5B%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%5D%20%5Cquad%20%5Cbecause%20%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Ctext%7B%20%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AF%B9%E7%A7%B0%E5%B9%82%E7%AD%89%E7%9F%A9%E9%98%B5%7D%20%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7BRank%7D%5Cleft%5B%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%5D%20%20%5C%5C%0A%26%3DN-r%0A%5Cend%7Baligned%7D%0A" /></p><p>我们再看右手项，在之前 ML 的推导中，我们知道 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29" style="display:inline-block;margin: 0;"/> ，因此我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%20%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%0A%26%3D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5C%5C%0A%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%20-%20%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%5E%7B%5Cprime%7D%20%5Cleft(%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%20-%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%20%5Cright)%5C%5C%0A%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%5Cquad%5Cleft(%5Cbecause%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright)%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cleft%5B%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Chat%7B%5Cmathbf%7BG%7D%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5Cright%5D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5Cleft%5B(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)-%5Cmathbf%7BZ%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Chat%7B%5Cmathbf%7BG%7D%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5Cright%5D%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5B(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%5D%5C%5C%0A%26%5Cleft(%5Cbecause%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%3D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Cmathbf%7BG%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D-%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%5Cright)%5Cright)%5C%5C%0A%26%3D%5Cfrac%7B1%7D%7B%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D)%0A%5Cend%7Baligned%7D%0A" /></p><p>因此，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%3D%5Cleft%28%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D-%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%5Cright%29%20%2F(N-r)%0A" /></p><p>同时，我们有 (SEARLE, 1979；缺证明)</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cleft%28%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%2B%5Coperatorname%7Btr%7D%20%5Cleft(%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5E%7Bi%20i%7D%5Cright%29%20%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%5Cright)%20%2F%20q_%7Bi%7D%0A" /></p><p>基于相同公式，另一种迭代公式为</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%7D%7Bq_%7Bi%7D-%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5E%7Bi%20i%7D%5Cright%29%20%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%2F%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%7D%20%20%0A" /></p><p>这里 <img src="https://math.now.sh?inline=q_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的水平数目；<img src="https://math.now.sh?inline=%5Csigma%5E%7B2%7D_%7Bi%7D%20%5Cmathbf%7BA%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的协方差矩阵；<img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D%5E%7Bi%20i%7D" style="display:inline-block;margin: 0;"/> 是系数矩阵的广义逆矩阵中第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 的随机效应对应的对角子矩阵；<img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的预测值。</p>
<p>通过上面这两个公式我们得到了 REML 的 EM 算法。在计算时，我们先给出一组初始的 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值，由混合模型方程组求出相应的 <img src="https://math.now.sh?inline=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D" style="display:inline-block;margin: 0;"/>  和 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7Bu%7D%7D" style="display:inline-block;margin: 0;"/> ，以及相应的系数矩阵逆矩阵元素；再由上面的两个公式求出一组新的  <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值，如此迭代下去，知道两次迭代得到的   <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值得差异小于给定阈值时，迭代收敛。</p>
<p>而且根据上面两个公式，可以得到 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 都比大于0（我看不出来），因此 EM 算法一定满足参数空间的要求。</p>
<h2 id="AI-算法">AI 算法</h2>
<p>首先我们看 Newton-Raphson 算法，其迭代公式为：</p>
<p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7B%5Ctheta%7D%5E%7B%28t%2B1%29%7D%3D%5Cboldsymbol%7B%5Ctheta%7D%5E%7B(t)%7D-%5Cleft(%5Cmathbf%7BH%7D%5E%7B(t)%7D%5Cright)%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Ctheta%7D%7D%20%5Cmid%20%5Cboldsymbol%7B%5Ctheta%7D%5E%7B(t)%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=L" style="display:inline-block;margin: 0;"/> 是需要最大化的原函数；<img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Ctheta%7D%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=L" style="display:inline-block;margin: 0;"/> 函数关于参数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Ctheta%7D" style="display:inline-block;margin: 0;"/> 的一阶偏导数向量；  <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=L" style="display:inline-block;margin: 0;"/> 函数关于参数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Ctheta%7D" style="display:inline-block;margin: 0;"/> 的二阶偏导数矩阵，即 Hessian 矩阵，举例如下</p>
<p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7BH%7D%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcccc%7D%0A%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B1%7D%5E%7B2%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B1%7D%20%5Cpartial%20%5Ctheta_%7B2%7D%7D%20%26%20%5Ccdots%20%26%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B1%7D%20%5Cpartial%20%5Ctheta_%7Bk%7D%7D%20%5C%5C%0A%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B1%7D%20%5Cpartial%20%5Ctheta_%7B2%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B2%7D%5E%7B2%7D%7D%20%26%20%5Ccdots%20%26%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B2%7D%20%5Cpartial%20%5Ctheta_%7Bk%7D%7D%20%5C%5C%0A%5Cvdots%20%26%20%5Cvdots%20%26%20%26%20%5Cvdots%20%5C%5C%0A%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B1%7D%20%5Cpartial%20%5Ctheta_%7Bk%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7B2%7D%20%5Cpartial%20%5Ctheta_%7Bk%7D%7D%20%26%20%5Ccdots%20%26%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Ctheta_%7Bk%7D%5E%7B2%7D%7D%0A%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p>由于计算 <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 矩阵的计算量较大，scoring 方法采用以下迭代公式，即采用  <img src="https://math.now.sh?inline=%5Cmathbf%7BF%7D" style="display:inline-block;margin: 0;"/> 矩阵替换  <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 矩阵。 <img src="https://math.now.sh?inline=%5Cmathbf%7BF%7D" style="display:inline-block;margin: 0;"/> 矩阵是  <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 矩阵的数学期望，即 <img src="https://math.now.sh?inline=%5Cboldsymbol%7BF%7D%3DE%28%5Cboldsymbol%7BH%7D%29" style="display:inline-block;margin: 0;"/> ；  <img src="https://math.now.sh?inline=-%20%5Cmathbf%7BF%7D" style="display:inline-block;margin: 0;"/> 矩阵则称为 Fisher 信息矩阵</p>
<p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7B%5Ctheta%7D%5E%7B%28t%2B1%29%7D%3D%5Cboldsymbol%7B%5Ctheta%7D%5E%7B(t)%7D-%5Cleft(%5Cmathbf%7BF%7D%5E%7B(t)%7D%5Cright)%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Ctheta%7D%7D%20%5Cmid%20%5Cboldsymbol%7B%5Ctheta%7D%5E%7B(t)%7D%0A" /></p><p>所谓平均信息算法，就是将期望信息 (<img src="https://math.now.sh?inline=-%20%5Cmathbf%7BF%7D" style="display:inline-block;margin: 0;"/>) 和观察信息 (<img src="https://math.now.sh?inline=-%20%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/>) 平均起来，得到一个平均信息矩阵</p>
<p style=""><img src="https://math.now.sh?from=A%20%5Cboldsymbol%7BI%7D%3D%5Cfrac%7B-%5Cboldsymbol%7BF%7D%2B%28-%5Cboldsymbol%7BH%7D%29%7D%7B2%7D%0A" /></p><p>此时相应的迭代公式为</p>
<p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7B%5Ctheta%7D%5E%7B%28t%2B1%29%7D%3D%5Cboldsymbol%7B%5Ctheta%7D%5E%7B(t)%7D-%5Cleft(%5Cmathbf%7BAI%7D%5E%7B(t)%7D%5Cright)%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Ctheta%7D%7D%20%5Cmid%20%5Cboldsymbol%7B%5Ctheta%7D%5E%7B(t)%7D%0A" /></p><p>在前面的推导中，我们已知 REML 方法的似然函数为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cln%20L%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29%3D%26%20%5Cfrac%7Bn-r%7D%7B2%7D%20%5Cln%20(2%20%5Cpi)-%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%5Cleft%7C%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright%7C-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%20%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%20%5C%5C%0A%3D%26%20%5Cfrac%7Bn-r%7D%7B2%7D%20%5Cln%20(2%20%5Cpi)-%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%5Cleft%7C%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cleft(%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright)%20%5Cmathbf%7BK%7D%20%5Cright%7C%20%5C%5C%0A%26-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft%5B%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cleft(%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright)%20%5Cmathbf%7BK%7D%5Cright%5D%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>举个例子，假设模型中随机效应只有加性效应（<img src="https://math.now.sh?inline=%5Cmathbf%7BG%7D%20%3D%20%5Cmathbf%7BA%7D%20%5Csigma%5E%7B2%7D_%7Ba%7D" style="display:inline-block;margin: 0;"/> ）和残差 (<img src="https://math.now.sh?inline=%5Cmathbf%7BR%7D%20%3D%20%5Cmathbf%7BI%7D%20%5Csigma%5E%7B2%7D_%7Be%7D" style="display:inline-block;margin: 0;"/>)，此时 Searle (1970) 证明  <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 矩阵为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cboldsymbol%7BH%7D%20%26%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0A%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%5Cleft%28%5Csigma_%7Ba%7D%5E%7B2%7D%5Cright%29%5E%7B2%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20%5Ccdot%7D%7B%5Cpartial%20%5Csigma_%7Ba%7D%5E%7B2%7D%20%5Cpartial%20%5Csigma_%7Be%7D%5E%7B2%7D%7D%20%5C%5C%0A%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%20%5Csigma_%7B%5Cmathrm%7Ba%7D%7D%5E%7B2%7D%20%5Cpartial%20%5Csigma_%7Be%7D%5E%7B2%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20L%7D%7B%5Cpartial%5Cleft(%5Csigma_%7Be%7D%5E%7B2%7D%5Cright)%5E%7B2%7D%7D%0A%5Cend%7Barray%7D%5Cright%5D%20%5C%5C%0A%26%5C%5C%0A%26%3D%5Cfrac%7B1%7D%7B2%7D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0A%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%5Cright)-2%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7By%7D%20%26%20%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%5Cright)-2%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20P%7D%20%5Cboldsymbol%7By%7D%20%5C%5C%0A%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%5Cright)-2%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20P%7D%20%5Cboldsymbol%7By%7D%20%26%20%5Coperatorname%7Btr%7D(%5Cboldsymbol%7BP%20P%7D)-2%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%20P%20P%7D%20%5Cboldsymbol%7By%7D%0A%5Cend%7Barray%7D%5Cright%5D%0A%5Cend%7Baligned%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B*%7D%20%3D%20%5Cmathbf%7BZAZ'%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BF%7D" style="display:inline-block;margin: 0;"/> 矩阵为</p>
<p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7BF%7D%3DE%28%5Cboldsymbol%7BH%7D%29%3D-%5Cfrac%7B1%7D%7B2%7D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0A%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%20%5E%7B*%7D%5Cright)%20%26%20%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%5Cright)%20%5C%5C%0A%5Coperatorname%7Btr%7D(%5Cboldsymbol%7BP%20V%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D)%20%26%20%5Coperatorname%7Btr%7D(%5Cboldsymbol%7BP%20P%7D)%0A%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p>其中左上角元素推导过程如下，其余元素同理（下面有一处应该有误，$ \boldsymbol{P X}= \boldsymbol{0} $ 不成立）。</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0AE%5Cleft%5B%5Coperatorname%7Btr%7D%5Cleft%28%5Cboldsymbol%7BP%20V%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20V%7D%5E%7B*%7D%5Cright%29-2%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7By%7D%5Cright%5D%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%20%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%5Cright)-2%20E%5Cleft(%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20V%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7By%7D%5Cright)%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%20%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%5Cright)-2%5B%5Coperatorname%7Btr%7D(%5Cboldsymbol%7BP%20V%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20V%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20V%7D)%20%5Cleft.%2B%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BX%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20X%7D%20%5Cboldsymbol%7B%5Cbeta%7D%5Cright%5D%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%5Cright)-2%20%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%5Cright)%20%20%5Cquad%20%5Cbecause%20%5Ctext%20%7B%20%7D%20%5Cboldsymbol%7BP%20V%20P%7D%3D%5Cboldsymbol%7BP%7D%2C%20%5Cboldsymbol%7BP%20X%7D%3D%20%5Cboldsymbol%7B0%7D%20%20%5C%5C%0A%26%3D-%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BP%20V%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20V%7D%5E%7B*%7D%5Cright)%20%0A%5Cend%7Baligned%7D%0A" /></p><p>此时平均信息矩阵为</p>
<p style=""><img src="https://math.now.sh?from=A%20%5Cboldsymbol%7BI%7D%3D%5Cfrac%7B-%5Cboldsymbol%7BF%7D%2B%28-%5Cboldsymbol%7BH%7D%29%7D%7B2%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0A%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7By%7D%20%26%20%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20P%7D%20%5Cboldsymbol%7By%7D%20%5C%5C%0A%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%7D%20%5Cboldsymbol%7BV%7D%5E%7B*%7D%20%5Cboldsymbol%7BP%20P%7D%20%5Cboldsymbol%7By%7D%20%26%20%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%20P%20P%7D%20%5Cboldsymbol%7By%7D%0A%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p>此时在 AI 算法中，不涉及迹函数的运算，计算难度相对低一点。</p>
<p>对于迭代公式中用到的一阶偏导数 <img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Ctheta%7D%7D" style="display:inline-block;margin: 0;"/> ，Johnson 和 Thompson (1995) 年证明存在下式</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Csigma_%7Ba%7D%5E%7B2%7D%7D%20%26%3D-0.5%20%5Coperatorname%7Btr%7D%5Cleft%28%5Cboldsymbol%7BP%20Z%20A%20%7D%20%5Cboldsymbol%7BZ%7D%5E%7B%5Cprime%7D%5Cright%29%2B0.5%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%20Z%20A%20Z%20%5E%20%7B%20%5Cprime%20%7D%20%5Cboldsymbol%20%7B%20P%20%7D%20%5Cboldsymbol%20%7B%20y%20%7D%7D%20%5C%5C%0A%26%3D-0.5%5Cleft%5B%5Cfrac%7Bq%7D%7B%5Csigma_%7Ba%7D%5E%7B2%7D%7D-%5Cfrac%7B%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BA%7D%5E%7B-1%7D%20%5Cboldsymbol%7BC%7D%5E%7B22%7D%5Cright)%7D%7B%5Csigma_%7Ba%7D%5E%7B4%7D%7D-%5Cfrac%7B%5Chat%7B%5Cmathbf%7Be%7D%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BZ%7D%20%5Chat%7B%5Cmathbf%7Ba%7D%7D%7D%7B%5Csigma_%7Be%7D%5E%7B2%7D%20%5Csigma_%7Ba%7D%5E%7B2%7D%7D%5Cright%5D%20%5C%5C%0A%26%5C%5C%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Csigma_%7Be%7D%5E%7B2%7D%7D%20%26%3D-0.5%20%5Coperatorname%7Btr%7D(%5Cboldsymbol%7BP%7D)%2B0.5%20%5Cboldsymbol%7By%7D%5E%7B%5Cprime%7D%20%5Cboldsymbol%7BP%20P%7D%20%5Cboldsymbol%7By%7D%20%5C%5C%0A%26%3D-0.5%5Cleft%5B%5Cfrac%7BN-r(%5Cboldsymbol%7BX%7D)%7D%7B%5Csigma_%7Be%7D%5E%7B2%7D%7D-%5Cleft(q-%5Cfrac%7B%5Coperatorname%7Btr%7D%5Cleft(%5Cboldsymbol%7BA%7D%5E%7B-1%7D%20%5Cboldsymbol%7BC%7D%5E%7B22%7D%5Cright)%7D%7B%5Csigma_%7Ba%7D%5E%7B4%7D%7D%5Cright)%20%5Cfrac%7B1%7D%7B%5Csigma_%7Be%7D%5E%7B2%7D%7D-%5Cfrac%7B%5Chat%7B%5Cmathbf%7Be%7D%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7Be%7D%7D%7D%7B%5Csigma_%7Be%7D%5E%7B4%7D%7D%5Cright%5D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>综上所述，可用如下步骤来实现 AI 算法，我们先给出一组初始的 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值，由混合模型方程组求出相应的 <img src="https://math.now.sh?inline=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D" style="display:inline-block;margin: 0;"/>  和 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7Bu%7D%7D" style="display:inline-block;margin: 0;"/> ，以及相应的系数矩阵逆矩阵元素；再计算出 <img src="https://math.now.sh?inline=%5Cmathbf%7BAI%7D" style="display:inline-block;margin: 0;"/> 矩阵和一阶偏导数向量，再求出一组新的  <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值，如此迭代下去，知道两次迭代得到的   <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值得差异小于给定阈值时，迭代收敛。</p>
<h2 id="DF-算法">DF 算法</h2>
<p>非求导算法 (deritative-free, DF) 顾名思义即不计算导数对于不同的参数直接计算似然函数值，从中找到使得似然函数最大的一组参数。</p>
<h1>参考文献</h1>
<ol>
<li>Rencher A C, Schaalje G B. Linear models in statistics[M]. John Wiley &amp; Sons, 2008.</li>
<li>Patterson H D, Thompson R. Recovery of inter-block information when block sizes are unequal[J]. Biometrika, 1971, 58(3): 545-554.</li>
<li>Hofer A. Variance component estimation in animal breeding: a review[J]. Journal of Animal Breeding and Genetics, 1998, 115(1‐6): 247-265.</li>
<li>Misztal I. Reliable computing in estimation of variance components[J]. Journal of animal breeding and genetics, 2008, 125(6): 363-370.</li>
<li>Searle S R. An overview of variance component estimation[J]. Metrika, 1995, 42(1): 215-230.</li>
<li>Notes on variance components estimation-A detailed account of maximum likelihood and kindred methodology</li>
<li>张沅, 张勤, 家畜育种. 畜禽育种中的线性模型[M]. 北京农业大学出版社, 1993.</li>
<li>Searle S R, Casella G, McCulloch C E. Variance components[M]. John Wiley &amp; Sons, 2009.</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/" rel="tag">理论学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" rel="tag">线性模型</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/posts/a6f7095/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            方差组分估计的普遍观点与启发
          
        </div>
      </a>
    
    
      <a href="/posts/e0b3b4ee/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">基因组选择模型介绍下</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "yHN3kf7fHt5wvleM2DVoHLdY-gzGzoHsz",
    app_key: "RPIwmdftljIzOtAULwc7JCAp",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "靓仔，看完留个评论再走哇！\n只需要填入昵称和邮箱就可以了",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2019-2023
        <i class="ri-heart-fill heart_icon"></i> Vincere Zhou
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>

    <!-- 与只只在一起天数 -->
	<ul>
		<li><span id="lovetime_span"></span></li>
	</ul>
    <script type="text/javascript">			
        function show_runtime() {
            window.setTimeout("show_runtime()", 1000);
            X = new Date("03/04/2021 22:11:00");
            Y = new Date();
            T = (Y.getTime() - X.getTime());
            M = 24 * 60 * 60 * 1000;
            a = T / M;
            A = Math.floor(a);
            b = (a - A) * 24;
            B = Math.floor(b);
            c = (b - B) * 60;
            C = Math.floor((b - B) * 60);
            D = Math.floor((c - C) * 60);
            lovetime_span.innerHTML = "只只和男朋友在一起了 " + A + "天" + B + "小时" + C + "分" + D + "秒"
        }
        show_runtime();
    </script>

  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/mojie.jpg" alt=""></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯茶吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/weixinpay.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300,"hOffset":80,"vOffset":-70},"mobile":{"show":false,"scale":0.5},"log":false});</script></body>

</html>