<!DOCTYPE html>


<html lang="zh-CN">


<head>
  <meta name="baidu-site-verification" content="codeva-NSg7ynviLa" />
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    方差组分估计方法二之ML和REML |  
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/images/mojie.jpg" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">
  
<link rel="stylesheet" href="/css/custom.css">

  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  

<link rel="alternate" href="/atom.xml" title="null" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-方差组分估计方法二之ML和REML"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  方差组分估计方法二之ML和REML
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/posts/eba70c/" class="article-date">
  <time datetime="2023-06-21T02:42:56.000Z" itemprop="datePublished">2023-06-21</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/">理论学习</a> / <a class="article-category-link" href="/categories/%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/">线性模型</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">5.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">18 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>这是方差组分估计方法的第二篇博客，介绍ML和REML两种方法及一些很早之前的算法。</p>
<span id="more"></span>
<h1>ML</h1>
<p>在最大似然方法中，我们需要新增分布假设，一般我们都采用<strong>正态假设</strong>，因此模型假设为 (这里假设所有随机效应的协方差矩阵均为对角矩阵)</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7By%7D%20%5Ctext%20%7B%20is%20%7D%20N_%7Bn%7D%28%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%2C%20%5Cmathbf%7BV%7D%29%2C%20%5Cquad%20%5Ctext%20%7B%20where%20%7D%20%5Cquad%20%5Cmathbf%7BV%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%2B%5Csigma%5E%7B2%7D%20%5Cmathbf%7BI%7D_%7Bn%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=n%20%5Ctimes%20p" style="display:inline-block;margin: 0;"/> 并且秩为 <img src="https://math.now.sh?inline=r%20%5Cleq%20p" style="display:inline-block;margin: 0;"/> 的矩阵。<img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cmathbf%7BV%7D%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=n%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/> 的<strong>正定</strong>矩阵。为了方便书写，我们记 <img src="https://math.now.sh?inline=%5Csigma_%7B0%7D%5E%7B2%7D%3D%5Csigma%5E%7B2%7D" style="display:inline-block;margin: 0;"/> ， <img src="https://math.now.sh?inline=%5Cmathbf%7BZ%7D_%7B0%7D%3D%5Cmathbf%7BI%7D_%7Bn%7D" style="display:inline-block;margin: 0;"/> ，因此协方差矩阵变成 (假设随机向量之间互不相关)</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BV%7D%3D%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%0A" /></p><p>随机向量 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 的联合分布密度函数，即似然函数为</p>
<p style=""><img src="https://math.now.sh?from=L%28%5Cmathbf%7By%7D%29%3D%5Cfrac%7B1%7D%7B(2%20%5Cpi)%5E%7Bn%20%2F%202%7D%7C%5Cmathbf%7BV%7D%7C%5E%7B1%20%2F%202%7D%7D%20%5Cexp%20%5Cleft%5C%7B-0.5(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%5Cright%5C%7D%0A" /></p><p>其对数为</p>
<p style=""><img src="https://math.now.sh?from=l%3D-0.5%20n%20%5Ctimes%20%5Cln%20%282%20%5Cpi%29-0.5%20%5Cln%20%7C%5Cmathbf%7BV%7D%7C-0.5(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cbeta)%0A" /></p><p>对他求未知参数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cboldsymbol%7B%5Ctheta%7D%7D%5E%7B%5Cprime%7D%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Blllll%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%5Cprime%7D%20%26%20%5Csigma_%7B0%7D%5E%7B2%7D%20%26%20%5Csigma_%7B1%7D%5E%7B2%7D%20%26%20%5Ccdots%20%26%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cend%7Barray%7D%5Cright%5D'" style="display:inline-block;margin: 0;"/> 的偏导数如下（证明略）</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Cfrac%7B%5Cpartial%20l%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Cbeta%7D%7D%3D-%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D-%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright%29%20%5C%5C%0A%26%5Cfrac%7B%5Cpartial%20l%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cright)%2B%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%20%5C%5C%0A%26%5Cleft(%5Cbecause%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cln%20%7C%5Cmathbf%7BV%7D%7C%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cright)%2C%20%5Cquad%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%3D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%5Cright)%20%5Cquad%20%5Ctext%7B%E5%8F%82%E8%80%83%20linear%20models%20in%20statistics%20%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>令上面两式为0，我们设 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D_%7Bi%7D%3D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%3D%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，因此我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%20%26%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%20%5C%5C%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%20%26%3D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%0A%5Cend%7Baligned%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> ，因为下式成立</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%26%3D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%5Cright)%20%5Cmathbf%7By%7D%20%5C%5C%0A%26%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%5Cleft(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright)%20%5C%5C%0A%26%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%0A%5Cend%7Baligned%7D%0A" /></p><p>因为</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5Cright)%3D%5Csum_%7Bj%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%20%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright)%0A" /></p><p>故有 ML 的估计方程为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Csum_%7Bj%7D%20%5Cleft%5C%7B%5Coperatorname%7Btr%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%3D%5Cleft%5C%7B%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%5Cright%5C%7D%20%5C%5C%0A%26i%2C%20j%3D0%2C1%2C%20%5Ccdots%2C%20m%0A%5Cend%7Baligned%7D%0A" /></p><p>这个式子还可以换一种形式，对于左手项：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%20%5Csum_%7Bj%7D%20%5Cleft%5C%7B%5Coperatorname%7Btr%7D%20%5Cleft%28%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%20%5Cright%29%20%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%20%5C%5C%0A%26%3D%5Csum_%7Bj%7D%20%5Cleft%5C%7B%5Coperatorname%7Btr%7D%20%5Cleft(%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%20%5Cmathbf%7BZ%7D_%7Bj%7D%5Cmathbf%7BZ%7D_%7Bj%7D%5E%7B%5Cprime%7D%20%5Cright)%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%20%5C%5C%0A%26%20%3D%20%5Csum_%7Bj%7D%20%5Cleft%5C%7B%5Coperatorname%7Btr%7D%20%20%5Cleft(%20%5Cmathbf%7BZ%7D_%7Bj%7D%5E%7B%5Cprime%7D%20(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D)%5Cright)%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%20%5C%5C%0A%26%20%3D%20%5Csum_%7Bj%7D%20%5Cleft%5C%7B%5Coperatorname%7Btr%7D%5Cleft(%20%20(%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D)%5E%7B%5Cprime%7D%20(%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D)%5Cright)%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%20%5C%5C%0A%26%20%3D%20%5Csum_%7Bj%7D%20%5Cleft%5C%7B%20%5Cmathbb%7Bsesq%7D%20(%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D)%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%20%5C%5C%0A%0A%5Cend%7Baligned%7D%0A" /></p><p>这里的 <img src="https://math.now.sh?inline=%5Cmathbb%7Bsesq%28%5Cmathbf%7BA%7D%29%7D" style="display:inline-block;margin: 0;"/> 就是矩阵 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 所有元素的平方和。</p>
<p>同理右手项可以写为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%3D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%3D%20%5Cmathrm%7Bsesq%7D%28%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%29%0A" /></p><p>因此，上面的式子可以写为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Csum_%7Bj%7D%20%5Cleft%5C%7B%20%5Cmathrm%7Bsesq%7D%20%28%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D%29%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%3D%5Cmathrm%7Bsesq%7D(%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D)%20%5C%5C%0A%26i%2C%20j%3D0%2C1%2C%20%5Ccdots%2C%20m%0A%5Cend%7Baligned%7D%0A" /></p><p>很显然这个式子不是 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 的线性方程组，左手项的 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 和右手项的 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D" style="display:inline-block;margin: 0;"/> 均包含<img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 。根据此式子，我们显然找不到闭式解，还需要采用迭代的方式求解。我们可以设置  <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Csigma%7D%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 的一个初始值，然后得到 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D" style="display:inline-block;margin: 0;"/> ，此时上面的方程组就变成了线性方程组，就可以求解得到一组新的   <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Csigma%7D%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>似然法的一个缺点式，当数据量比较小时，其估计值时有偏的。而且随着固定效应水平数目的增加和随机效应水平数目的减少，其偏差会愈加严重。</p>
<h2 id="估计值的方差">估计值的方差</h2>
<p>由于 ML 估计值必须通过迭代求解得到，因此不可能求得估计值的准确的抽样方差，但当样本数目较大时，可以求得估计值的近似方差（称为<strong>大样本方差</strong>）。这个方差是借助参数的<strong>信息矩阵</strong>来求得的，参数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Ctheta%7D" style="display:inline-block;margin: 0;"/> 的信息矩阵用 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29" style="display:inline-block;margin: 0;"/> 表示，其定义为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BI%7D%28%5Cboldsymbol%7B%5Ctheta%7D%29%20%3D%20-%20%5Coperatorname%7BE%7D%5Cleft%5C%7B%20%5Cfrac%7B%5Cpartial%5E%7B2%7D%20l%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Ctheta%7D%20%5Cpartial%20%5Cboldsymbol%7B%5Ctheta%7D%5E%7B%5Cprime%7D%20%7D%20%5Cright%5C%7D%0A" /></p><p>其为二阶导的数学期望的负值。</p>
<p>Searle (1970) 证明，当样本数目足够大时，参数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Ctheta%7D" style="display:inline-block;margin: 0;"/> 的 ML 估计值  <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Ctheta%7D%7D" style="display:inline-block;margin: 0;"/> 的方差近似为：</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Bvar%7D%20%28%5Cboldsymbol%7B%5Chat%7B%5Ctheta%7D%7D%29%20%5Capprox%20%5Cleft%5B%5Cmathbf%7BI%7D(%5Cboldsymbol%7B%5Ctheta%7D)%20%5Cright%5D%5E%7B-1%7D%0A" /></p><p>注意这式子本身并不需要 ML 估计值   <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Ctheta%7D%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>ML 估计值的信息矩阵写为下式，其中 <img src="https://math.now.sh?inline=l_%7B%5Cboldsymbol%7B%5Cbeta%7D%20%5Cboldsymbol%7B%5Cbeta%7D%7D" style="display:inline-block;margin: 0;"/> 表示 <img src="https://math.now.sh?inline=%5Cpartial%5E%7B2%7D%20l%2F%5Cpartial%20%5Cboldsymbol%7B%5Cbeta%7D%20%5Cpartial%20%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，其余式子类似。</p>
<p style=""><img src="https://math.now.sh?from=I%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cboldsymbol%7B%5Cbeta%7D%20%5C%5C%0A%5Cboldsymbol%7B%5Csigma%7D%5E2%0A%5Cend%7Barray%7D%5Cright%5D%3D-E%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0Al_%7B%5Cboldsymbol%7B%5Cbeta%7D%20%5Cboldsymbol%7B%5Cbeta%7D%7D%20%26%20l_%7B%5Cboldsymbol%7B%5Cbeta%7D%20%5Cboldsymbol%7B%5Csigma%7D%5E2%7D%20%5C%5C%0Al_%7B%5Cboldsymbol%7B%5Csigma%7D%5E2%20%5Cboldsymbol%7B%5Cbeta%7D%7D%20%26%20l_%7B%5Cboldsymbol%7B%5Csigma%7D%5E2%20%5Cboldsymbol%7B%5Csigma%7D%5E2%7D%0A%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p>因为我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20l%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Cbeta%7D%7D%3D-%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D-%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright%29%0A" /></p><p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%3D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%3D%20-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%0A" /></p><p>因此，推导得到</p>
<p style=""><img src="https://math.now.sh?from=l_%7B%5Cboldsymbol%7B%5Cbeta%7D%20%5Cboldsymbol%7B%5Cbeta%7D%7D%20%3D%20-%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%0A" /></p><p style=""><img src="https://math.now.sh?from=l_%7B%5Cboldsymbol%7B%5Cbeta%7D%20%5Cboldsymbol%7B%5Csigma%7D_%7Bi%7D%5E2%7D%20%3D%20-%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%28%5Cmathbf%7By%7D%20-%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%29%0A" /></p><p>同时我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20l%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%29%2B%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%0A" /></p><p>因此，推导得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0Al_%7B%5Cboldsymbol%7B%5Csigma%7D_%7Bi%7D%5E2%20%5Cboldsymbol%7B%5Csigma%7D_%7Bj%7D%5E2%7D%20%26%3D%20%5Cfrac%7B1%7D%7B2%7D%5Coperatorname%7Btr%7D%28%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D%5Cmathbf%7BZ%7D_%7Bj%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%29%20-%20%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D%5Cmathbf%7BZ%7D_%7Bj%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%20%5C%5C%0A%26%20%5Cquad%20-%20%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D%5Cmathbf%7BZ%7D_%7Bj%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%20%5C%5C%0A%26%3D%20%5Cfrac%7B1%7D%7B2%7D%5Coperatorname%7Btr%7D(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D%5Cmathbf%7BZ%7D_%7Bj%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D)%20-%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D%5Cmathbf%7BZ%7D_%7Bj%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>然后再计算期望，我们已知 <img src="https://math.now.sh?inline=%5Coperatorname%7BE%7D%28%5Cmathbf%7By%7D%29%20%3D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D" style="display:inline-block;margin: 0;"/> ，即 <img src="https://math.now.sh?inline=%5Coperatorname%7BE%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%29%20%3D%20%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/>。我们再利用一个公式 <img src="https://math.now.sh?inline=%5Coperatorname%7BE%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%29%5E%7B%5Cprime%7D%20%5Cmathbf%7BT%7D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%20%3D%20%5Coperatorname%7Btr%7D%20(%5Cmathbf%7BTV%7D)" style="display:inline-block;margin: 0;"/> ,  其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BT%7D" style="display:inline-block;margin: 0;"/> 是一个非随机的矩阵。</p>
<p>证明过程如下，将 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D" style="display:inline-block;margin: 0;"/> 改成为 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cmu%7D" style="display:inline-block;margin: 0;"/></p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Coperatorname%7BE%7D%28%5Cmathbf%7By%7D-%5Cboldsymbol%7B%5Cmu%7D%29%5E%7B%5Cprime%7D%20%5Cmathbf%7BT%7D%20(%5Cmathbf%7By%7D-%5Cboldsymbol%7B%5Cmu%7D)%20%5C%5C%0A%26%3D%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D-%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D)%20%20(%5Cmathbf%7By%7D-%5Cboldsymbol%7B%5Cmu%7D)%20%5C%5C%0A%26%3D%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cmathbf%7By%7D-%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cmathbf%7By%7D%20-%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cboldsymbol%7B%5Cmu%7D%20%2B%20%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%20%5Cboldsymbol%7B%5Cmu%7D)%20%5C%5C%0A%26%3D%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cmathbf%7By%7D)-%5Coperatorname%7BE%7D(%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cmathbf%7By%7D)%20-%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cboldsymbol%7B%5Cmu%7D)%20%2B%20%5Coperatorname%7BE%7D(%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%20%5Cboldsymbol%7B%5Cmu%7D)%20%5C%5C%0A%26%3D%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cmathbf%7By%7D)-%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D)%20-%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D)%5Cmathbf%7BT%7D%5Cboldsymbol%7B%5Cmu%7D%20%2B%20%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%20%5Cboldsymbol%7B%5Cmu%7D%20%5C%5C%0A%26%3D%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cmathbf%7By%7D)-%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%20%5Cboldsymbol%7B%5Cmu%7D%20%5C%5C%0A%26%3D%20%5Coperatorname%7Btr%7D%20(%5Cmathbf%7BTV%7D)%2B%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%20%5Cboldsymbol%7B%5Cmu%7D-%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%20%5Cboldsymbol%7B%5Cmu%7D%20%5Cquad%20%5Cbecause%20%5Coperatorname%7BE%7D(%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%5Cmathbf%7By%7D)%20%3D%20%5Coperatorname%7Btr%7D%20(%5Cmathbf%7BTV%7D)%2B%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%5Cmathbf%7BT%7D%20%5Cboldsymbol%7B%5Cmu%7D%20%5C%5C%0A%0A%26%3D%20%5Coperatorname%7Btr%7D%20(%5Cmathbf%7BTV%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>因此我们得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A-E%20l_%7B%5Cboldsymbol%7B%5Cbeta%7D%20%5Cboldsymbol%7B%5Cbeta%7D%7D%20%26%20%3DE%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%2C%20%5C%5C%0A-E%20l_%7B%5Cboldsymbol%7B%5Cbeta%7D%20%5Csigma_i%5E2%7D%20%26%20%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20E(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%3D%5Cmathbf%7B0%7D%20%5C%5C%0A-E%20l_%7B%5Csigma_i%5E2%20%5Csigma_j%5E2%7D%20%26%20%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%5Cright)%2B%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D%5Cright)%20%5C%5C%0A%26%20%3D%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%5Cright)%20%0A%5Cend%7Baligned%7D%0A" /></p><p>因此信息矩阵为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BI%7D%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cboldsymbol%7B%5Cbeta%7D%20%5C%5C%0A%5Cboldsymbol%7B%5Csigma%7D%5E2%0A%5Cend%7Barray%7D%5Cright%5D%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0A%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%26%20%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%26%20%5Cfrac%7B1%7D%7B2%7D%5Cleft%5C%7B_%5Cmathrm%7Bm%7D%20%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%5Cright%29%5Cright%5C%7D_%7Bi%2C%20j%3D0%7D%0A%5Cend%7Barray%7D%5Cright%5D%20.%0A" /></p><p>因此估计值的协方差矩阵为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Bvar%7D%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cboldsymbol%7B%5Cbeta%7D%20%5C%5C%0A%5Ctilde%7B%5Csigma%7D%5E2%0A%5Cend%7Barray%7D%5Cright%5D%20%26%20%5Csimeq%5Cleft%28%5Cmathbf%7BI%7D%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cboldsymbol%7B%5Cbeta%7D%20%5C%5C%0A%5Cboldsymbol%7B%5Csigma%7D%5E2%0A%5Cend%7Barray%7D%5Cright%5D%5Cright%29%5E%7B-1%7D%20%5C%5C%0A%26%20%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0A%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-1%7D%20%26%20%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%26%202%5Cleft%5B%5Cleft%5C%7B%5Cmathrm%7B~m%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%5Cright)%5Cright%5C%7D_%7Bi%2C%20j%3D0%7D%5Er%5Cright%5D%5E%7B-1%7D%0A%5Cend%7Barray%7D%5Cright%5D%2C%0A%5Cend%7Baligned%7D%0A" /></p><h2 id="The-Hartley-Rao-form">The Hartley-Rao form</h2>
<p>Hartley 和 Rao 在 1967 年提出了基于 <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 矩阵的似然函数，其中  <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 矩阵定义为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BV%7D%20%3D%20%5Cmathbf%7BH%7D%20%5Csigma_%7Be%7D%5E%7B2%7D%20%5Cqquad%20%5Ctext%7Bwith%7D%20%5Cqquad%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%3D%20%5Cmathbf%7BH%7D%5E%7B-1%7D%2F%20%5Csigma_%7Be%7D%5E%7B2%7D%0A" /></p><p>因此  <img src="https://math.now.sh?inline=%5Cmathbf%7BH%7D" style="display:inline-block;margin: 0;"/> 矩阵和  <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D" style="display:inline-block;margin: 0;"/> 矩阵具有相同的形式，不过 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D" style="display:inline-block;margin: 0;"/> 矩阵中的 <img src="https://math.now.sh?inline=%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 变成了1，而  <img src="https://math.now.sh?inline=%5Csigma_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 变成了 <img src="https://math.now.sh?inline=%5Cgamma_%7Bi%7D%20%3D%20%5Csigma_%7Bi%7D%5E%7B2%7D%2F%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> ，这意味着此时需要估计的参数为 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cbeta%7D" style="display:inline-block;margin: 0;"/> ，<img src="https://math.now.sh?inline=%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cgamma_%7B1%7D%2C%20%5Ccdots%2C%20%5Cgamma_%7Br%7D" style="display:inline-block;margin: 0;"/> (这里的 <img src="https://math.now.sh?inline=r" style="display:inline-block;margin: 0;"/> 就是上面的 <img src="https://math.now.sh?inline=m" style="display:inline-block;margin: 0;"/> ，随机效应数目)，此时我们将 <img src="https://math.now.sh?inline=%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 单独拎了出来。</p>
<p>我们从之前的公式 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%29%20%0A%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> 出发进行推导，首先，当 <img src="https://math.now.sh?inline=i%3D0" style="display:inline-block;margin: 0;"/> 时，此时 <img src="https://math.now.sh?inline=%5Csigma_%7B0%7D%5E%7B2%7D%20%3D%20%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/>，<img src="https://math.now.sh?inline=%5Cmathbf%7BZ%7D_%7B0%7D%20%3D%20%5Cmathbf%7BI%7D" style="display:inline-block;margin: 0;"/> ，因此我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cright%29%20%0A%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5E%7B2%7D%20%7B%5Cmathbf%7By%7D%7D%20%3D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%0A" /></p><p>代入 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%7D%20%3D%20%5Cmathbf%7BH%7D%5E%7B-1%7D%2F%20%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> ，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BH%7D%7D%5E%7B-1%7D%20%5Cright%29%20%0A%3D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BH%7D%7D%5E%7B-2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%2F%20%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%0A" /></p><p>因此</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20%3D%20%5Cfrac%7B%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BH%7D%7D%5E%7B-2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%7D%7B%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BH%7D%7D%5E%7B-1%7D%20%5Cright)%7D%0A" /></p><p>然后我们继续看其它方差组分 (<img src="https://math.now.sh?inline=i%3D1%2C%5Ccdots%2Cr" style="display:inline-block;margin: 0;"/>) 的式子，对于公式 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%29%20%0A%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> ，左右乘以  <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 并对 <img src="https://math.now.sh?inline=i%3D1%2C%5Ccdots%2Cr" style="display:inline-block;margin: 0;"/> 的式子求和得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Cright%29%20%0A%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cleft(%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Cright)%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%0A" /></p><p>代入<img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%7D%20%3D%20%5Cmathbf%7BH%7D%5E%7B-1%7D%2F%20%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> ， <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%0A%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29" style="display:inline-block;margin: 0;"/> 以及 <img src="https://math.now.sh?inline=%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%3D%20%5Cmathbf%7BV%7D%20-%20%5Csigma_%7Be%7D%5E%7B2%7D%5Cmathbf%7BI%7D%3D%20%28%5Cmathbf%7BH%7D%20-%20%5Cmathbf%7BI%7D%29%5Csigma_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> ，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28(%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%2F%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%29%20%20(%5Cmathbf%7B%5Chat%7BH%7D%7D%20-%20%5Cmathbf%7BI%7D)%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20%5Cright)%20%0A%3D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%2F%20%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20(%5Cmathbf%7B%5Chat%7BH%7D%7D%20-%20%5Cmathbf%7BI%7D)%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%2F%20%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%0A" /></p><p>化简得到</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BI%7D%20-%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20%5Cright%29%20%0A%3D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%20(%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20-%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-2%7D)%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%2F%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%0A" /></p><p>等价于</p>
<p style=""><img src="https://math.now.sh?from=N%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20%3D%20%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%5E%7B%5Cprime%7D%20%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%2B%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20%5Cright)%20%5Cleft%5B%20%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20-%20%5Cfrac%7B(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-2%7D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%7D%7B%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20%5Cright)%7D%20%20%5Cright%5D%0A" /></p><p>根据上面的推导公式，方括号内的值为 0，因此我们得到 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 的计算公式</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20%3D%20%5Cfrac%7B%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%5E%7B%5Cprime%7D%20%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%7D%7BN%7D%0A" /></p><p>对于公式 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%29%20%0A%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> ，化简得到</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BH%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%29%20%0A%3D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%2F%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%0A" /></p><p>汇总一下，Hartley 和 Rao 方法中设计的方程组为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%20%26%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%20%5C%5C%0A%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20%26%3D%20%5Cfrac%7B%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%5E%7B%5Cprime%7D%20%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%7D%7BN%7D%20%5C%5C%0A%26%5Ctext%7Band%7D%20%5C%5C%0A%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BH%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright)%20%0A%26%3D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BH%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%2F%5Chat%7B%5Csigma%7D_%7Be%7D%5E%7B2%7D%20%5C%5C%0A%26i%3D1%2C%20%5Ccdots%2C%20r%0A%0A%5Cend%7Baligned%7D%0A" /></p><h2 id="EM-算法">EM 算法</h2>
<p>混合详细模型如下：</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7By%7D%20%3D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%20%2B%20%5Cmathbf%7BZ%7D%5Cmathbf%7Bu%7D%20%2B%20%5Cmathbf%7Be%7D%0A" /></p><p>对于公式 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> ，我们在等式两边同乘以 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D%5E%7B2%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> ，并求总和，得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Csum%20%5Cmathbf%7B%5Chat%7BV%7D%7D_%7Bi%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%5Cright%29%20%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Csum%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%20%5C%5C%0AN%20%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%20%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>这里 <img src="https://math.now.sh?inline=N" style="display:inline-block;margin: 0;"/> 为 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D" style="display:inline-block;margin: 0;"/> 矩阵维度，即表型数目。</p>
<p>我们再看右手项，在之前 ML 的推导中，我们知道 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29" style="display:inline-block;margin: 0;"/> ，因此我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%20%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%0A%26%3D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5C%5C%0A%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%20-%20%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%5E%7B%5Cprime%7D%20%5Cleft(%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%20-%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%20%5Cright)%5C%5C%0A%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%5Cquad%5Cleft(%5Cbecause%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright)%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cleft%5B%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Chat%7B%5Cmathbf%7BG%7D%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5Cright%5D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5Cleft%5B(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)-%5Cmathbf%7BZ%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Chat%7B%5Cmathbf%7BG%7D%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5Cright%5D%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5B(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%5D%5C%5C%0A%26%5Cleft(%5Cbecause%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%3D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Cmathbf%7BG%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D-%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%5Cright)%5Cright)%5C%5C%0A%26%3D%5Cfrac%7B1%7D%7B%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D)%20%5Cquad%20%5Cbecause%20%5Ctext%7B%E5%81%87%E8%AE%BE%E4%B8%BA%E5%8D%95%E6%80%A7%E7%8A%B6%E6%A8%A1%E5%9E%8B%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>因此，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%29%20%2FN%0A" /></p><p>其它方差组分公式的证明过程如下</p>
<p>首先我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Bvar%7D%28%5Cmathbf%7Be%7D%29%20%3D%20%5Cmathbf%7BR%7D%20%3D%20%5Csigma_%7Be%7D%5E%7B2%7D%5Cmathbf%7BI%7D_%7BN%7D%20%5Cquad%20%5Ctext%7Band%7D%20%5Cquad%20%5Coperatorname%7Bvar%7D(%5Cmathbf%7Bu%7D)%20%3D%20%5Cmathbf%7BG%7D%20%3D%20%5Cleft%5C%7B_%7Bd%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%0A" /></p><p>这里我们进一步提出两个矩阵 <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7BF%7D_%7Bii%7D" style="display:inline-block;margin: 0;"/> 矩阵，第一个矩阵如下，其中 <img src="https://math.now.sh?inline=q_%7B.%7D%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20q_%7Bi%7D" style="display:inline-block;margin: 0;"/> ，即所有随机效应水平总数。</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BW%7D%20%3D%20%28%5Cmathbf%7BI%2BZ'R%5E%7B-1%7DZG%7D%29%5E%7B-1%7D%20%3D%20%5Cleft%5C%7B%20%5Cmathbf%7BW%7D_%7Bij%7D%20%5Cright%5C%7D_%7Bi%2Cj%3D1%7D%5E%7Br%7D%20%5Cquad%20%5Ctext%7Bwith%7D%20%5Cquad%20%5Cmathbf%7BW%7D%5E%7B-1%7D%20-%20%5Cmathbf%7BI%7D_%7Bq_%7B.%7D%7D%20%3D%20%5Cmathbf%7BZ'R%5E%7B-1%7DZG%7D%0A" /></p><p>第二个矩阵是 <img src="https://math.now.sh?inline=%5Cmathbf%7BG%7D" style="display:inline-block;margin: 0;"/> 矩阵的变体， <img src="https://math.now.sh?inline=%5Cmathbf%7BF%7D_%7Bii%7D" style="display:inline-block;margin: 0;"/> 是将 <img src="https://math.now.sh?inline=%5Cmathbf%7BG%7D" style="display:inline-block;margin: 0;"/> 矩阵中的所有 <img src="https://math.now.sh?inline=%5Csigma_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 替换为 1，而其它 <img src="https://math.now.sh?inline=%5Csigma_%7Bj%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> (<img src="https://math.now.sh?inline=j%20%5Cneq%20i" style="display:inline-block;margin: 0;"/> ) 替换为0 （注意这里的  <img src="https://math.now.sh?inline=%5Cmathbf%7BG%7D" style="display:inline-block;margin: 0;"/> 矩阵是一个对角矩阵），因此我没有</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BG%7D%5Cmathbf%7BF%7D_%7Bii%7D%20%3D%20%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BF%7D_%7Bii%7D%20%5Cquad%20%5Ctext%7Band%7D%20%5Cquad%20%5Cmathbf%7BF%7D_%7Bii%7D%20%3D%20%5Cmathbf%7BG%7D%5Cmathbf%7BF%7D_%7Bii%7D%2F%5Csigma_%7Bi%7D%5E%7B2%7D%0A" /></p><p>举个例子，假设 <img src="https://math.now.sh?inline=q_%7B1%7D%3D2%2C%20q_%7B2%7D%3D3%2Cq_%7B3%7D%3D4" style="display:inline-block;margin: 0;"/> ，那么我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BF_%7B22%7D%7D%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bccc%7D%0A%5Cmathbf%7B0%7D_%7B2%20%5Ctimes%202%7D%20%26%20%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7B1%7D_%7B3%20%5Ctimes%203%7D%20%26%20%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7B0%7D_%7B4%20%5Ctimes%204%7D%0A%5Cend%7Barray%7D%5Cright%5D%20%5Ctext%20%7B.%20%7D%0A" /></p><p>根据 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 公式，我们可以推导出</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BV%7D%5E%7B-1%7D%20%26%3D%20%5Cmathbf%7BR%7D%5E%7B-1%7D-%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cleft%28%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Cmathbf%7BG%7D%5E%7B-1%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5C%5C%0A%26%3D%20%20%5Cmathbf%7BR%7D%5E%7B-1%7D-%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cleft(%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%20%2B%20%5Cmathbf%7BI%7D%20%5Cright)%20%5Cmathbf%7BG%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5C%5C%0A%26%3D%20%20%5Cmathbf%7BR%7D%5E%7B-1%7D-%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cmathbf%7BG%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%20%2B%20%5Cmathbf%7BI%7D%20%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5C%5C%0A%26%3D%20%20%5Cmathbf%7BR%7D%5E%7B-1%7D-%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cmathbf%7BG%7D%5Cmathbf%7BW%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>对于其它方程组分我们有  <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> 的左手项，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%29%20%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cleft(%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%5Cright)%20%5Cleft(%20%5Cmathbf%7BF%7D_%7Bii%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cright)%5Cright)%20%5C%5C%0A%20%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%5E%7B2%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%5Cright)%20%5C%5C%0A%20%20%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%5Cright)%20%5C%5C%0A%20%20%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%20%20%5Cright)%20%5C%5C%0A%20%20%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%5Cleft%5B%5Cmathbf%7B%5Chat%7BR%7D%7D%5E%7B-1%7D-%5Cmathbf%7B%5Chat%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cmathbf%7B%5Chat%7BG%7D%7D%5Cmathbf%7BW%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BR%7D%7D%5E%7B-1%7D%20%5Cright%5D%20%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%20%20%5Cright)%20%5C%5C%0A%20%20%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cleft%5B%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7B%5Chat%7BG%7D%7D%20-%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cmathbf%7B%5Chat%7BG%7D%7D%5Cmathbf%7BW%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B%5Chat%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cmathbf%7B%5Chat%7BG%7D%7D%20%5Cright%5D%20%20%5Cmathbf%7BF%7D_%7Bii%7D%2F%5Csigma_%7Bi%7D%5E%7B2%7D%20%20%5Cright)%20%5Cquad%20%5Cbecause%20%5Cmathbf%7BF%7D_%7Bii%7D%20%3D%20%5Cmathbf%7BG%7D%5Cmathbf%7BF%7D_%7Bii%7D%2F%5Csigma_%7Bi%7D%5E%7B2%7D%20%5C%5C%0A%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cleft%5B%20%5Cmathbf%7BW%7D%5E%7B-1%7D%20-%20%5Cmathbf%7BI%7D%20-%5Cleft(%20%5Cmathbf%7BW%7D%5E%7B-1%7D%20-%20%5Cmathbf%7BI%7D%20%5Cright)%5Cmathbf%7BW%7D%20%5Cleft(%20%5Cmathbf%7BW%7D%5E%7B-1%7D%20-%20%5Cmathbf%7BI%7D%20%5Cright)%20%5Cright%5D%20%20%5Cmathbf%7BF%7D_%7Bii%7D%2F%5Csigma_%7Bi%7D%5E%7B2%7D%20%20%5Cright)%20%20%5C%5C%0A%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cleft(%20%5Cmathbf%7BI%7D%20-%20%5Cmathbf%7BW%7D%20%5Cright)%20%20%5Cmathbf%7BF%7D_%7Bii%7D%2F%5Csigma_%7Bi%7D%5E%7B2%7D%20%20%5Cright)%20%20%5C%5C%0A%26%3D%20%5Coperatorname%7Btr%7D%5Cleft(%20%5Cmathbf%7BF%7D_%7Bii%7D%20-%20%5Cmathbf%7BW%7D%20%20%20%5Cmathbf%7BF%7D_%7Bii%7D%20%20%5Cright)%20%2F%5Csigma_%7Bi%7D%5E%7B2%7D%20%5C%5C%0A%26%3D%20%5Cfrac%7B%20%5Cmathbf%7Bq%7D_%7Bi%7D%20-%20%5Coperatorname%7Btr%7D%20%5Cleft(%5Cmathbf%7BW%7D_%7Bii%7D%5Cright)%7D%20%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5C%5C%0A%0A%5Cend%7Baligned%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D_%7Bii%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D" style="display:inline-block;margin: 0;"/> 矩阵中第 <img src="https://math.now.sh?inline=%28i%2Ci%29" style="display:inline-block;margin: 0;"/> 个子矩阵。</p>
<p>右手项可以写为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%0A%26%20%3D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%5E%7B%5Cprime%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%5C%5C%0A%26%20%3D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7BG%7D%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BG%7D%7D%5E%7B%5Cprime%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%2F%20%5Csigma_%7Bi%7D%5E%7B4%7D%20%5C%5C%0A%26%20%3D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7BG%7D%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%20%20%5Chat%7B%5Cmathbf%7BG%7D%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%2F%20%5Csigma_%7Bi%7D%5E%7B4%7D%20%5C%5C%0A%0A%0A%5Cend%7Baligned%7D%0A" /></p><p>因为 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BG%7D%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%3D%20%5Chat%7B%5Cmathbf%7BG%7D%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%3D%20%5Chat%7B%5Cmathbf%7BG%7D%7D%20%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%20%3D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D" style="display:inline-block;margin: 0;"/></p>
<p>因此右手项可以继续写为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%20%3D%20%20%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BF%7D_%7Bii%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%7D%20%7B%5Csigma_%7Bi%7D%5E%7B4%7D%7D%20%3D%20%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D%5E%7B%5Cprime%7D_%7Bi%7D%20%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%7D%20%7B%5Csigma_%7Bi%7D%5E%7B4%7D%7D%0A" /></p><p>因此我们将   <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/>  改写为下式</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%20%5Cmathbf%7Bq%7D_%7Bi%7D%20-%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BW%7D_%7Bii%7D%5Cright%29%7D%20%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%3D%20%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D%5E%7B%5Cprime%7D_%7Bi%7D%20%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%7D%20%7B%5Csigma_%7Bi%7D%5E%7B4%7D%7D%0A" /></p><p>因此我们得到了两个迭代公式</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%2B%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BW%7D_%7Bii%7D%5Cright%29%20%7D%20%7Bq_%7Bi%7D%7D%0A" /></p><p>或者</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%7D%7Bq_%7Bi%7D-%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BW%7D_%7Bii%7D%5Cright%29%20%7D%0A" /></p><p>这里 <img src="https://math.now.sh?inline=q_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的水平数目；<img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的预测值。</p>
<p>同时使用公式</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%29%20%2FN%0A" /></p><h3 id="额外证明">额外证明</h3>
<ol>
<li>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D%20%3D%20%28%5Cmathbf%7BI%2BZ'R%5E%7B-1%7DZG%7D%29%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 矩阵存在，因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%2BZ'R%5E%7B-1%7DZG%7D" style="display:inline-block;margin: 0;"/> 的行列式等于 <img src="https://math.now.sh?inline=%7C%5Cmathbf%7BR%7D%5E%7B-1%7D%7C%7C%5Cmathbf%7BV%7D%7C%20%5Cneq%200" style="display:inline-block;margin: 0;"/> 。</p>
<p>不会证明。</p>
</li>
<li>
<p><img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BW%7D_%7Bii%7D%20%5Cright%29%20%3E%200" style="display:inline-block;margin: 0;"/></p>
<p>证明：</p>
<p>因为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%5Cmathbf%7BW%7D%5E%7B-1%7D%20%3D%20%5Cleft%28%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%20%5Cright%29%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%0A" /></p><p>其逆矩阵为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BW%7D%5Cmathbf%7BG%7D%5E%7B-1%2F2%7D%20%3D%5Cmathbf%7BG%7D%5E%7B-1%2F2%7D%20%5Cleft%28%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%20%5Cright%29%5E%7B-1%7D%0A" /></p><p>左右均乘以 <img src="https://math.now.sh?inline=%5Cmathbf%7BG%7D%5E%7B1%2F2%7D" style="display:inline-block;margin: 0;"/> 得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%5Cmathbf%7BW%7D%20%3D%20%5Cleft%28%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%20%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%20%3D%20%5Cleft(%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BT%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BT%7D%20%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%0A" /></p><p>这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BT%7D%20%3D%20%5Cmathbf%7BR%7D%5E%7B-1%2F2%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BT%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BT%7D" style="display:inline-block;margin: 0;"/> 是一个正定矩阵，因为其二次型 <img src="https://math.now.sh?inline=%5Cmathbf%7Bx%7D%5E%7B%5Cprime%7D%20%5Cleft%28%20%20%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BT%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BT%7D%20%5Cright%29%20%5Cmathbf%7Bx%7D%20%3D%20%5Cmathbf%7Bx%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bx%7D%20%2B%20(%5Cmathbf%7BT%7D%20%5Cmathbf%7Bx%7D)%5E%7B%5Cprime%7D%20(%5Cmathbf%7BT%7D%20%5Cmathbf%7Bx%7D)%20%3E%200" style="display:inline-block;margin: 0;"/> ，因此其逆矩阵   <img src="https://math.now.sh?inline=%28%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BT%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BT%7D%29%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 也是正定矩阵，其对角线元素均大于 0。<strong>因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BG%7D%5E%7B1%2F2%7D" style="display:inline-block;margin: 0;"/> 是一个对角矩阵</strong>，根据上面的公式 <img src="https://math.now.sh?inline=%5Cmathbf%7BG%7D%5E%7B1%2F2%7D%5Cmathbf%7BW%7D%20%3D%20%5Cleft%28%5Cmathbf%7BI%7D%20%2B%20%5Cmathbf%7BT%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BT%7D%20%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BG%7D%5E%7B1%2F2%7D" style="display:inline-block;margin: 0;"/> ，因此 <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D" style="display:inline-block;margin: 0;"/> 矩阵的对角线元素也均大于 0， 因此  <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D" style="display:inline-block;margin: 0;"/> 矩阵正定，因此 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BW%7D_%7Bii%7D%20%5Cright%29%20%3E%200" style="display:inline-block;margin: 0;"/>  。</p>
</li>
<li>
<p><img src="https://math.now.sh?inline=q_%7Bi%7D-%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BW%7D_%7Bii%7D%5Cright%29%20%5Cgeq%200" style="display:inline-block;margin: 0;"/></p>
<p>证明：根据上面的公式，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%20%5Cmathbf%7Bq%7D_%7Bi%7D%20-%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BW%7D_%7Bii%7D%5Cright%29%7D%20%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%3D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright)%20%3D%20%5Coperatorname%7Btr%7D%5Cleft(%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cright)%20%3D%20%5Coperatorname%7Btr%7D%5Cleft(%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cright)%20%3D%20%5Coperatorname%7Bvar%7D(%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D)%20%5Cgeq%200%0A" /></p><p>因此我们可以看出每一轮迭代产生的 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 均为正数，即均在参数空间中。（不知道如何证明 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%29%20%2FN" style="display:inline-block;margin: 0;"/> 大于 0  ）</p>
</li>
</ol>
<h1>REML</h1>
<p><strong>限制性最大似然</strong> (<em>restricted (residual) maximum likelihood</em>, REML) ，由  Patterson 和 Thompson 在 1971 年提出。我们强调 REML 方法的原因是在标准的线性模型中，样本方差 <img src="https://math.now.sh?inline=s%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 也是 REML 的估计值。同时，REML 是一种一般的方法，比如 REML 在不平衡数据中也可以使用。在某些平衡数据中，REML 可能有解析解 (闭式解)。REML 同时是<strong>最佳二次无偏估计值</strong>。</p>
<p>REML 的思想是对数据 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'y%7D" style="display:inline-block;margin: 0;"/> 进行最大似然估计，而不是 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> ，这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是我们人为挑选的，以使得  <img src="https://math.now.sh?inline=%5Cmathbf%7BK'y%7D" style="display:inline-block;margin: 0;"/> 的分布只包含方差组分，而不包含 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cbeta%7D" style="display:inline-block;margin: 0;"/> 。为了实现这一点，矩阵 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 需要满足 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20X%7D%3D%5Cmathbf%7BO%7D" style="display:inline-block;margin: 0;"/> ，因此 <img src="https://math.now.sh?inline=E%28%5Cmathbf%7BK'%20y%7D%29%3D%5Cmathbf%7BK'%20X%7D%5Cboldsymbol%7B%5Cbeta%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 。为了方便，我们同时要求  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是一个<strong>满秩</strong>矩阵。我们同时要求  <img src="https://math.now.sh?inline=%5Cmathbf%7BK'y%7D" style="display:inline-block;margin: 0;"/>  尽可能包含最多的关于方程组分的信息，因此  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 必须有最大的行数。</p>
<p><strong>定理</strong>：  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是一个满秩矩阵，满足 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20X%7D%3D%5Cmathbf%7BO%7D" style="display:inline-block;margin: 0;"/> ，但是同时拥有最大的行数，因此它是一个 <img src="https://math.now.sh?inline=%28n-r%29%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/> 的矩阵 (<img src="https://math.now.sh?inline=r" style="display:inline-block;margin: 0;"/> 为 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的秩)。进一步地说，<img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的形式必须为 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7BC%7D%28%5Cmathbf%7BI%7D-%5Cmathbf%7BH%7D%29%3D%5Cmathbf%7BC%7D%5Cleft%5B%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%5Cright%5D" style="display:inline-block;margin: 0;"/> ，这里  <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=%28n-r%29%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/>  的满秩矩阵。</p>
<p><strong>证明</strong>：<img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 的行 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 满足等式 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，转置得到 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7Bk%7D_%7Bi%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> （注意这里出现了符号重叠问题，这里的 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 行元素组成的列向量）。根据定理， <strong>如果线性方程组 <img src="https://math.now.sh?inline=Ax%20%3D%20c" style="display:inline-block;margin: 0;"/> 是相容的</strong>，那么所有可能的解为  <img src="https://math.now.sh?inline=%5Cmathbf%7Bx%7D%3D%5Cmathbf%7BA%7D%5E%7B-%7D%20%5Cmathbf%7Bc%7D%2B%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BA%7D%5E%7B-%7D%20%5Cmathbf%7BA%7D%5Cright%29%20%5Cmathbf%7Bh%7D" style="display:inline-block;margin: 0;"/>  ，这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 是某个特定的广义逆， <img src="https://math.now.sh?inline=h" style="display:inline-block;margin: 0;"/> 为所有可能的值组成的向量。因此，这里的方程组的解为 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%3D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5E%7B-'%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%5Cright%29%20%5Cmathbf%7Bc%7D" style="display:inline-block;margin: 0;"/> （书中有笔误，书里是 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%3D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5E%7B-%7D%20%5Cmathbf%7BX%7D%5Cright%29%20%5Cmathbf%7Bc%7D" style="display:inline-block;margin: 0;"/> ，这里又有符号重叠问题，这里的 <img src="https://math.now.sh?inline=%5Cmathbf%7Bc%7D" style="display:inline-block;margin: 0;"/> 就是上面定理中的 <img src="https://math.now.sh?inline=%5Cmathbf%7Bh%7D" style="display:inline-block;margin: 0;"/> ，为所有可能的 <img src="https://math.now.sh?inline=n%20%5Ctimes%201" style="display:inline-block;margin: 0;"/> 的向量） ，因此  <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7Bc%7D%5E%7B%5Cprime%7D%20%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29" style="display:inline-block;margin: 0;"/> ，也就是说 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 的行 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 的行的所有可能的线性组合。</p>
<p>我们知道  <img src="https://math.now.sh?inline=%5Coperatorname%7Brank%7D%5Cleft%28%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29%3D%5Coperatorname%7Brank%7D(%5Cmathbf%7BX%7D)%3Dr" style="display:inline-block;margin: 0;"/> ，并且 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29%5E%7B2%7D%20%3D%20%5Cmathbf%7BI%7D-2%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B-%7D%2B%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B-%7D%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/>  ，因此 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 是一个<strong>幂等</strong>矩阵，因此 <img src="https://math.now.sh?inline=%5Coperatorname%7Brank%7D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright)%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright)%3Dn-r" style="display:inline-block;margin: 0;"/> ，因此 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 的行的张成空间的维度为 <img src="https://math.now.sh?inline=n-r" style="display:inline-block;margin: 0;"/> ，因此最多有  <img src="https://math.now.sh?inline=n-r" style="display:inline-block;margin: 0;"/>  个线性无关的向量 <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，也就是说 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的行数最大为 <img src="https://math.now.sh?inline=n-r" style="display:inline-block;margin: 0;"/> 。</p>
<p>因为   <img src="https://math.now.sh?inline=%5Cmathbf%7Bk%7D_%7Bi%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7Bc%7D%5E%7B%5Cprime%7D%20%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29" style="display:inline-block;margin: 0;"/>  ，那么一定存在一个  <img src="https://math.now.sh?inline=%28n-r%29%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/>  的满秩矩阵   <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D" style="display:inline-block;margin: 0;"/>  ，使得  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵可以表示为 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7BC%7D%5Cleft%28%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D%5Cright%29" style="display:inline-block;margin: 0;"/> ，其中  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的每一行均是  <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 的行的线性组合，并且由于 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵满秩， 因此选择 <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D" style="display:inline-block;margin: 0;"/> 矩阵的标准是必须使得  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵的行之间线性无关。根据广义逆的性质，我们知道 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的一个广义逆，因此我们可以这里的 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 可以选择为  <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，因此此时  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵可以表示为 <img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D%28%5Cmathbf%7BI%7D-%5Cmathbf%7BH%7D%29%3D%5Cmathbf%7BC%7D%5Cleft%5B%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%5Cright%5D" style="display:inline-block;margin: 0;"/> 。</p>
<p>满足要求的  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 矩阵有无数个，但是这不影响我们使用。同时我们注意到校正固定效应的残差为 <img src="https://math.now.sh?inline=%5Chat%7B%5Cboldsymbol%7B%5Cvarepsilon%7D%7D%20%3D%20%28%5Cmathbf%7BI%7D-%5Cmathbf%7BH%7D%29%20%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> ，因此</p>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D%3D%5Cmathbf%7BC%7D%28%5Cmathbf%7BI%7D-%5Cmathbf%7BH%7D%29%20%5Cmathbf%7By%7D%20%3D%20%5Cmathbf%7BC%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cvarepsilon%7D%7D" style="display:inline-block;margin: 0;"/> 的每个元素都是所有残差的线性组合，这也是 <code>residual maximum likelihood</code> 这个名称的由来。</p>
<p>而 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D" style="display:inline-block;margin: 0;"/> 的分布见下面的定理。</p>
<p><strong>定理</strong>：在混合线性模型中，假设 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D%20%5Csim%20N_%7Bn%7D%28%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%2C%20%5Cmathbf%7BV%7D%29" style="display:inline-block;margin: 0;"/> ，其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%3D%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，那么</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BK'%20y%7D%20%5Csim%20%20N_%7Bn-r%7D%5Cleft%28%5Cmathbf%7B0%7D%2C%20%5Cmathbf%7BK'%20%5Cmathbf%7BV%7D%7D%20%5Cmathbf%7BK%7D%5Cright%29%0A" /></p><p>证明很简单，因为  <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 满足正态，所以 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D" style="display:inline-block;margin: 0;"/> 也满足正态，同时根据  <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20X%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 易得 <img src="https://math.now.sh?inline=%5Cmathbf%7BK'%20y%7D" style="display:inline-block;margin: 0;"/> 的均值为 <img src="https://math.now.sh?inline=%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> , 其方差为 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%7D%20%5Cmathbf%7BK%7D" style="display:inline-block;margin: 0;"/> ，得证。</p>
<p>因此  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D" style="display:inline-block;margin: 0;"/> 的分布只与 <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个方差组分有关。为了估计方差组分，REML 的下一步是针对这些方差组分最大化  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D" style="display:inline-block;margin: 0;"/> 的似然值。</p>
<p>对似然函数求偏导，使之为零，我们得到下面的定理。</p>
<p><strong>定理</strong>：在上面的模型中， <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个方差组分 <img src="https://math.now.sh?inline=%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 的估计值满足下面的方程组，其中 <img src="https://math.now.sh?inline=i%3D0%2C%20%5Cldots%2C%20m" style="display:inline-block;margin: 0;"/></p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%5B%5Cmathbf%7BK%7D%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%5D%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D%0A" /></p><p><strong>证明</strong>：因为 <img src="https://math.now.sh?inline=E%28%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%29%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，<img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D" style="display:inline-block;margin: 0;"/> 的对数似然值为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cln%20L%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29%3D%26%20%5Cfrac%7Bn-r%7D%7B2%7D%20%5Cln%20(2%20%5Cpi)-%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%5Cleft%7C%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright%7C-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%20%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%20%5C%5C%0A%3D%26%20%5Cfrac%7Bn-r%7D%7B2%7D%20%5Cln%20(2%20%5Cpi)-%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%5Cleft%7C%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cleft(%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright)%20%5Cmathbf%7BK%7D%20%5Cright%7C%20%5C%5C%0A%26-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft%5B%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cleft(%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright)%20%5Cmathbf%7BK%7D%5Cright%5D%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>根据矩阵求导的性质，假设 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=n%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/> 的<strong>非奇异矩阵</strong>，其元素 <img src="https://math.now.sh?inline=a_%7Bij%7D" style="display:inline-block;margin: 0;"/> 是关于标量 <img src="https://math.now.sh?inline=x" style="display:inline-block;margin: 0;"/> 的函数。我们定义  <img src="https://math.now.sh?inline=%5Cpartial%20%5Cmathbf%7BA%7D%20%2F%20%5Cpartial%20x" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=n%20%5Ctimes%20n" style="display:inline-block;margin: 0;"/> 的矩阵，其元素为 <img src="https://math.now.sh?inline=%5Cpartial%20a_%7Bi%20j%7D%20%2F%20%5Cpartial%20x" style="display:inline-block;margin: 0;"/> 。那么存在</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%5E%7B-1%7D%7D%7B%5Cpartial%20x%7D%3D-%5Cmathbf%7BA%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%7D%7B%5Cpartial%20x%7D%20%5Cmathbf%7BA%7D%5E%7B-1%7D%0A" /></p><p>和</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20%5Clog%20%7C%5Cmathbf%7BA%7D%7C%7D%7B%5Cpartial%20x%7D%3D%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BA%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%7D%7B%5Cpartial%20x%7D%5Cright%29%0A" /></p><p>利用这两条性质，我们求 <img src="https://math.now.sh?inline=%5Cln%20L%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29" style="display:inline-block;margin: 0;"/> 对每一个 <img src="https://math.now.sh?inline=%5Csigma_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 的偏导数，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5Cln%20L%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Cldots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29%3D%26-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cleft(%5Cmathbf%7BK%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%5Cleft%5B%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cleft(%5Cmathbf%7BK%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%7D%20%5Cmathbf%7BK%7D%5Cright)%5Cright%5D%5Cright)%20%5C%5C%0A%26%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%5Cleft%5B%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5Cright%5D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20y%7D%20%5C%5C%0A%3D%26-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft%5B%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cright%5D%20%5C%5C%0A%26%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D%20%5C%5C%0A%3D%26-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft%5B%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%5D%20%5C%5C%0A%26%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>将这个式子设为0，得到上面的结果。</p>
<p>证毕。</p>
<p>有一点很有意思，根据二次型的期望公式 <img src="https://math.now.sh?inline=E%5Cleft%28%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%20y%7D%5Cright%29%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BA%7D%20%5Cmathbf%7BV%7D)%2B%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D%20%5Cboldsymbol%7B%5Cmu%7D" style="display:inline-block;margin: 0;"/> ，上面式子的右手项的期望 (这里设期望公式里的 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 是  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%5E%7B%5Cprime%7Dy%7D" style="display:inline-block;margin: 0;"/>  ，<img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D%20%3D%20%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%20%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> )  正好是左手项。</p>
<p>SEARLE (1979) 证明</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BK%7D%20%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%20K%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7BP%7D%0A" /></p><p>证明如下：</p>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%3D%5Cmathbf%7BK%7D%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/>  和 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%3D%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 是对称幂等矩阵，对称证明略，幂等证明如下，<img src="https://math.now.sh?inline=%28%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%29%5E%7B2%7D%20%3D%20%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%20%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%20%20%3D%20%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D" style="display:inline-block;margin: 0;"/> 。我们已知 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，因此 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 并且 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%20%5Cmathbf%7BK%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 。因此</p>
<p><img src="https://math.now.sh?inline=%5Cmathbf%7BT%7D%3D%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D" style="display:inline-block;margin: 0;"/> 是一个对称幂等矩阵，幂等证明如下（其实直接根据对称幂等矩阵的性质即可证明，如果 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 对称幂等，那么 <img src="https://math.now.sh?inline=%5Cmathbf%7BI-A%7D" style="display:inline-block;margin: 0;"/> 对称幂等 ）：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Cleft%28%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5Cright%29%5Cleft(%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5Cright)%20%5C%5C%0A%26%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%2B%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%2B%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20-%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%2B%20%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%20%2B%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5C%5C%0A%26%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%2B%20%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D%20%20-%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%20%20%2B%20%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5C%5C%0A%26%3D%20%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%20%5Cmathbf%7BX%7D%5E%7B%2B%7D-%5Cmathbf%7BK%7D%20%5Cmathbf%7BK%7D%5E%7B%2B%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>因此</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BT%20T%7D%5E%7B%5Cprime%7D%5Cright%29%3D%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BT%7D%5E%7B2%7D%5Cright)%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BT%7D)%20%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%5Cright)-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%5Cright)%20%5C%5C%0A%26%3DN-r_%7B%5Cmathbf%7BX%7D%7D-r_%7B%5Cmathbf%7BK%7D%7D%20%5C%5C%0A%26%3DN-r_%7B%5Cmathbf%7BX%7D%7D-%5Cleft(N-r_%7B%5Cmathbf%7BX%7D%7D%5Cright)%20%5C%5C%0A%26%3D0%0A%5Cend%7Baligned%7D%0A" /></p><p>根据幂等矩阵的性质，我们知道幂等矩阵的秩等于迹，因此  <img src="https://math.now.sh?inline=%5Coperatorname%7Brank%7D%28%5Cmathbf%7BT%7D%29%20%3D%200" style="display:inline-block;margin: 0;"/> ，说明 <img src="https://math.now.sh?inline=%5Cmathbf%7BT%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> （只有零矩阵的秩为 0）。因此，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%3D%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D%0A" /></p><p>因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D" style="display:inline-block;margin: 0;"/> 是一个正定矩阵，因此总是存在 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B1%2F2%7D" style="display:inline-block;margin: 0;"/> 矩阵使得 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%20%3D%20%28%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%29%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 。那么由于  <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/>  ，那么我们知道 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%20%5Cmathbf%7BX%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，之前适应 <img src="https://math.now.sh?inline=%5Cmathbf%7BK%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的结果均适用于 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%20%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 。我们替换 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%20X%7D%5E%7B%2B%7D%3D%5Cmathbf%7BK%20K%7D%5E%7B%2B%7D" style="display:inline-block;margin: 0;"/> 中的MP逆矩阵，我们得到 <img src="https://math.now.sh?inline=%5Cmathbf%7BI%7D-%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%3D%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 。将  <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%20%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/>  带入得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BI%7D-%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B%2B%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%2F2%7D%3D%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B1%2F2%7D%0A" /></p><p>因此 （<strong>注意下面的 <img src="https://math.now.sh?inline=%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D" style="display:inline-block;margin: 0;"/> 是 MP 逆</strong> ）</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BP%7D%3D%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%3D%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%0A" /></p><p>得证。</p>
<p>其中 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/>  ，将该式带入，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D%0A" /></p><p>注意最大似然法的估计公式为 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%20%0A%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> ，因此 <strong>REML 方法相比与 ML 方法就是将左手项的 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 替换为 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Chat%7BP%7D%7D" style="display:inline-block;margin: 0;"/> 。</strong></p>
<p>我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BPVP%7D%20%26%3D%20%5Cleft%28%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cright)%20%5Cmathbf%7BV%7D%20%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cright)%20%5C%5C%0A%0A%26%3D%20%5Cleft(%5Cmathbf%7BI%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%20%5Cright)%20%5Cleft(%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cright)%20%5C%5C%0A%0A%26%3D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20-%20%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%2B%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5C%5C%0A%0A%26%3D%20%5Cmathbf%7BP%7D%20%5Cquad%20%5Cbecause%20%20%5Ctext%7B%E8%AE%BE%7D%20%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Ctext%7B%E6%98%AF%E8%87%AA%E5%8F%8D%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>因此，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright)%20%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Cmathbf%7BP%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5Cright)%20%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%5Cright)%20%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%20%5C%5C%0A%26%3D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bj%7D%5Cright)%20%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>因而，对于 <img src="https://math.now.sh?inline=i%2Cj%20%3D%200%2C1%2C%5Ccdots%2C%20m" style="display:inline-block;margin: 0;"/> ，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%5Cleft%5C%7B%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%7B%5Cmathbf%7BV%7D_%7Bj%7D%7D%5Cright%29%5Cright%5C%7D%5Cleft%5C%7B%5Chat%7B%5Csigma%7D_%7Bj%7D%5E%7B2%7D%5Cright%5C%7D%3D%5Cleft%5C%7B%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%5Cright%5C%7D%0A" /></p><p>这就是 REML 的估计方程，它也必须通过迭代求解。</p>
<p>根据这个定理，我们可以得到 <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个方程，而我们总共有 <img src="https://math.now.sh?inline=m%2B1" style="display:inline-block;margin: 0;"/> 个未知数。在某些情况下，这些方程组可以进一步简化从而得到闭式解。但是在大多数情况下，这些方程组是无法直接求解的。</p>
<p>我们一般会用一些迭代的方法来进行估计 (Rao 1997 pp. 104 – 105, McCulloch and Searle 2001, pp. 265 – 269)。我们注意到上面定理中的 <img src="https://math.now.sh?inline=m%20%2B1" style="display:inline-block;margin: 0;"/> 个方程组成的方程组可以写为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BM%7D%20%5Cboldsymbol%7B%5Csigma%7D%3D%5Cmathbf%7Bq%7D%0A" /></p><p>这里 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D%3D%5Cleft%28%5Csigma_%7B0%7D%5E%7B2%7D%2C%20%5Csigma_%7B1%7D%5E%7B2%7D%2C%20%5Ccdots%2C%20%5Csigma_%7Bm%7D%5E%7B2%7D%5Cright%29%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D" style="display:inline-block;margin: 0;"/> 是一个<strong>非奇异</strong>的  <img src="https://math.now.sh?inline=%28m%2B1%29%20%5Ctimes(m%2B1)" style="display:inline-block;margin: 0;"/> 的矩阵，其中的元素 <img src="https://math.now.sh?inline=M_%7Bij%7D%3D%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%7B%5Cmathbf%7BV%7D_%7Bj%7D%7D%5Cright%29" style="display:inline-block;margin: 0;"/> ，然后 <img src="https://math.now.sh?inline=%5Cmathbf%7Bq%7D" style="display:inline-block;margin: 0;"/> 是一个 <img src="https://math.now.sh?inline=%28m%2B1%29%20%5Ctimes%201" style="display:inline-block;margin: 0;"/> 的向量，其中的元素  <img src="https://math.now.sh?inline=q_%7Bi%7D%20%3D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>我们注意到 <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D%20%5Cboldsymbol%7B%5Csigma%7D%3D%5Cmathbf%7Bq%7D" style="display:inline-block;margin: 0;"/> 这个式子貌似更加复杂，因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D" style="display:inline-block;margin: 0;"/>  和 <img src="https://math.now.sh?inline=%5Cmathbf%7Bq%7D" style="display:inline-block;margin: 0;"/> 中都含有未知数 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D" style="display:inline-block;margin: 0;"/> 。然而，这个方程组对于我们从一个初始值 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D_%7B%281%29%7D" style="display:inline-block;margin: 0;"/> 逐步迭代来估计的方式而言很有用。我们在第 <img src="https://math.now.sh?inline=t" style="display:inline-block;margin: 0;"/> 步可以用 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D_%7B%28t%29%7D" style="display:inline-block;margin: 0;"/> 来计算  <img src="https://math.now.sh?inline=%5Cmathbf%7BM%7D_%7B%28t%29%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7Bq%7D_%7B%28t%29%7D" style="display:inline-block;margin: 0;"/> ，那么 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Csigma%7D_%7B%28t%2B1%29%7D%3D%5Cmathbf%7BM%7D_%7B(t)%7D%5E%7B-1%7D%20%5Cmathbf%7Bq%7D_%7B(t)%7D" style="display:inline-block;margin: 0;"/> ，然后一直迭代直到收敛。</p>
<h2 id="估计值的方差-2">估计值的方差</h2>
<p>首先我们证明</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BP%7D%7D%7B%5Cpartial%20%5Csigma_i%5E2%7D%20%26%20%3D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_i%5E2%7D%20%5Cmathbf%7BK%7D%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5C%5C%0A%26%20%3D%5Cmathbf%7BK%7D%20%5Cleft(%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma_i%5E2%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cright)%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cquad%20%5Cbecause%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BA%7D%20%5Cmathbf%7BQ%7D%20%7D%7B%5Cpartial%20x%7D%20%20%3D%20%5Cmathbf%7BP%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%7D%7B%5Cpartial%20x%7D%20%5Cmathbf%7BQ%7D%20%5C%5C%0A%26%20%3D-%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%20%5Cright)%5E%7B-1%7D%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%7D%7B%5Cpartial%20%5Csigma_i%5E2%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cquad%20%5Cbecause%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%5E%7B-1%7D%7D%7B%5Cpartial%20x%7D%3D-%5Cmathbf%7BA%7D%5E%7B-1%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%7D%7B%5Cpartial%20x%7D%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5C%5C%0A%26%20%3D-%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_i%5E2%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%20K%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5C%5C%0A%26%20%3D-%5Cmathbf%7BP%7D%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BV%7D%7D%7B%5Cpartial%20%5Csigma_i%5E2%7D%20%5Cmathbf%7BP%7D%5C%5C%0A%26%3D-%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>我们已知</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%20l_%7B%5Cmathbf%7BR%7D%7D%7D%7B%5Cpartial%20%5Csigma_i%5E2%7D%20%0A%26%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft%5B%5Cmathbf%7BK%7D%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cright%5D%20%5C%5C%0A%26%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%5E%7B%5Cprime%7D%20Z%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D%5C%5C%0A%0A%26%20%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BP%7D%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright)%2B%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20y%7D%20%0A%5Cend%7Baligned%7D%0A" /></p><p>求二阶导得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%5E2%20I_%7BR%7D%7D%7B%5Cpartial%20%5Csigma_i%5E2%20%5Cpartial%20%5Csigma_j%5E2%7D%20%26%20%3D%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BP%20Z%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright%29-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_j%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20y%7D-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20%7D%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20y%7D%20%5C%5C%0A%26%20%3D%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BP%20Z%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20%7D%20%5Cmathbf%7BZ%7D_i%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright)-%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20y%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>这里利用了两个性质：<img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20%5Coperatorname%7Btr%7D%20%28%5Cmathbf%7BA%7D%20%5Cmathbf%7BB%7D%29%20%7D%7B%5Cpartial%20x%7D%20%20%3D%20%5Coperatorname%7Btr%7D%20(%5Cmathbf%7BA%7D%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BB%7D%20%7D%7B%5Cpartial%20x%7D)%20%2B%20%5Coperatorname%7Btr%7D%20(%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D%20%7D%7B%5Cpartial%20x%7D%5Cmathbf%7BB%7D)" style="display:inline-block;margin: 0;"/> 和  <img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D_%7B1%7D%20%5Cmathbf%7BA%7D_%7B2%7D%20%5Ccdots%20%5Cmathbf%7BA%7D_%7Bn%7D%20%7D%7B%5Cpartial%20x%7D%20%20%3D%20%28%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D_%7B1%7D%7D%7B%5Cpartial%20x%7D%20%5Cmathbf%7BA%7D_%7B2%7D%20%5Ccdots%20%5Cmathbf%7BA%7D_%7Bn%7D%29%2B%5Ccdots%2B(%20%5Cmathbf%7BA%7D_%7B1%7D%20%5Cmathbf%7BA%7D_%7B2%7D%20%5Ccdots%20%5Cfrac%7B%5Cpartial%20%5Cmathbf%7BA%7D_%7Bn%7D%7D%7B%5Cpartial%20x%7D)" style="display:inline-block;margin: 0;"/> ，证明过程参考 Linear models in statistics 。</p>
<p>再求期望得到信息矩阵， 这里利用二次型的期望公式 <img src="https://math.now.sh?inline=E%5Cleft%28%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%20y%7D%5Cright%29%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BA%7D%20%5Cmathbf%7BV%7D)%2B%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D%20%5Cboldsymbol%7B%5Cmu%7D%20." style="display:inline-block;margin: 0;"/></p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%20-E%5Cleft%28%5Cfrac%7B%5Cpartial%5E2%20l_%7B%5Cmathbf%7BR%7D%7D%7D%7B%5Cpartial%20%5Csigma_i%5E2%20%5Csigma_j%5E2%7D%5Cright%29%5C%5C%0A%26%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BP%20Z%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20Z_%7B%20i%20%7D%7D%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright)%2B%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BP%20Z%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20%7D%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20V%7D%5Cright)-%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20%7D%20%5Cmathbf%7BZ%7D_j%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20Z%20_%20%7B%20i%20%7D%7D%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20X%7D%20%5Cboldsymbol%7B%5Cbeta%7D%20%5C%5C%0A%26%20%3D-%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BP%20Z%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20Z%20_%20%7B%20i%20%7D%7D%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright)%2B%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20Z%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20V%20P%7D%5Cright)%2B%5Cmathbf%7B0%7D%20%5Cquad%20%5Ctext%20%7B%2C%20because%20%7D%20%5Cmathbf%7BP%20X%7D%3D%20%5Cmathbf%7BK%7D%20%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%20K%7D%5Cright)%5E%7B-1%7D%20(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D)%3D%5Cmathbf%7B0%7D%20%5Ctext%20%7B%2C%20%7D%20%5C%5C%0A%26%20%3D%5Cfrac%7B1%7D%7B2%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BP%20Z%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%20Z%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright)%20%5Cquad%20%20%5Ctext%20%7B%2C%20because%20%7D%20%5Cmathbf%7BP%20V%20P%7D%3D%5Cmathbf%7BP%7D%20.%20%5C%5C%0A%26%0A%5Cend%7Baligned%7D%0A" /></p><p>因此估计值的协方差矩阵为</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Bvar%7D%5Cleft%28%5Ctilde%7B%5Csigma%7D_%7B%5Cmathrm%7BREML%7D%7D%5E2%5Cright%29%20%26%20%5Csimeq%202%5Cleft%5B%5Cleft%5C%7B_%7B%5Cmathrm%7Bm%7D%7D%20%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_j%20%5Cmathbf%7BZ%7D_j%5E%7B%5Cprime%7D%5Cright)%5Cright%5C%7D_%7Bi%2C%20j%3D0%7D%5Er%5Cright%5D%5E%7B-1%7D%20%5C%5C%0A%26%20%5Csimeq%202%5Cleft%5B%5Cleft%5C%7B_%7B%5Cmathrm%7Bm%7D%7D%20%5Coperatorname%7Bsesq%7D%5Cleft(%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_j%5Cright)%5Cright%5C%7D_%7Bi%2C%20j%3D0%7D%5Er%5Cright%5D%5E%7B-1%7D%2C%0A%5Cend%7Baligned%7D%0A" /></p><p>这和 ML 的式子格式相同，只是将 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 替换成了 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D" style="display:inline-block;margin: 0;"/> 。</p>
<h2 id="EM-算法-2">EM 算法</h2>
<p>混合详细模型如下：</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7By%7D%20%3D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%20%2B%20%5Cmathbf%7BZ%7D%5Cmathbf%7Bu%7D%20%2B%20%5Cmathbf%7Be%7D%0A" /></p><p>对于公式 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> ，我们在等式两边同乘以 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D%5E%7B2%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> ，并求总和，得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%5Cleft%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Csum%20%5Cmathbf%7B%5Chat%7BV%7D%7D_%7Bi%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%5Cright%29%20%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Csum%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%20%5C%5C%0A%5Coperatorname%7Btr%7D%5Cleft(%5Chat%7B%5Cmathbf%7BP%7D%7D%20%20%5Cmathbf%7B%5Chat%7BV%7D%7D%5Cright)%20%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%20%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>我们先看左手项 (下面的 <strong><img src="https://math.now.sh?inline=N" style="display:inline-block;margin: 0;"/> 是表型数目，<img src="https://math.now.sh?inline=r" style="display:inline-block;margin: 0;"/> 为 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 的秩</strong>)</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Coperatorname%7Btr%7D%28%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%29%20%26%3D%5Coperatorname%7Btr%7D%5Cleft%5B%5Cleft(%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%5Cright)%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5Cright%5D%20%5C%5C%0A%0A%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft%5B%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cright%5D%20%5C%5C%0A%0A%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7Btr%7D%5Cleft%5B%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%5D%20%5Cquad%20%5Cbecause%20%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Ctext%7B%20%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AF%B9%E7%A7%B0%E5%B9%82%E7%AD%89%E7%9F%A9%E9%98%B5%7D%20%5C%5C%0A%26%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BI%7D)-%5Coperatorname%7BRank%7D%5Cleft%5B%5Cleft(%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%5D%20%20%5C%5C%0A%26%3DN-r%0A%5Cend%7Baligned%7D%0A" /></p><p>我们再看右手项，在之前 ML 的推导中，我们知道 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7By%7D%20%3D%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29" style="display:inline-block;margin: 0;"/> ，因此我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BP%7D%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%20%20%5Chat%7B%5Cmathbf%7BP%7D%7D%5Cmathbf%7By%7D%0A%26%3D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%29%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5C%5C%0A%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%20-%20%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%5E%7B%5Cprime%7D%20%5Cleft(%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%20-%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%20%5Cright)%5C%5C%0A%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%20%5Cquad%5Cleft(%5Cbecause%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%3D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D%5Cright)%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cleft%5B%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D-%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Chat%7B%5Cmathbf%7BG%7D%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5Cright%5D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5Cleft%5B(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)-%5Cmathbf%7BZ%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Chat%7B%5Cmathbf%7BG%7D%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)%5Cright%5D%5C%5C%0A%26%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7BR%7D%7D%5E%7B-1%7D%5B(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D)-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%5D%5C%5C%0A%26%5Cleft(%5Cbecause%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%3D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%2B%5Cmathbf%7BG%7D%5E%7B-1%7D%5Cright)%5E%7B-1%7D%5Cleft(%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7By%7D-%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D%5Cright)%5Cright)%5C%5C%0A%26%3D%5Cfrac%7B1%7D%7B%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%7D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D)%20%5Cquad%20%5Cbecause%20%5Ctext%7B%E5%81%87%E8%AE%BE%E4%B8%BA%E5%8D%95%E6%80%A7%E7%8A%B6%E6%A8%A1%E5%9E%8B%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>因此，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%3D%5Cleft%28%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7By%7D-%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BX%7D%20%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D-%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BZ%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D%5Cright%29%20%2F(N-r)%0A" /></p><p>同时，我们有 (SEARLE, 1979)</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cleft%28%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%2B%5Coperatorname%7Btr%7D%20%5Cleft(%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5E%7Bi%20i%7D%5Cright%29%20%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%5Cright)%20%2F%20q_%7Bi%7D%0A" /></p><p>基于相同公式，另一种迭代公式为</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%7D%7Bq_%7Bi%7D-%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BA%7D_%7Bi%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5E%7Bi%20i%7D%5Cright%29%20%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%2F%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%7D%0A" /></p><p>这里 <img src="https://math.now.sh?inline=q_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的水平数目；<img src="https://math.now.sh?inline=%5Csigma%5E%7B2%7D_%7Bi%7D%20%5Cmathbf%7BA%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的协方差矩阵；<img src="https://math.now.sh?inline=%5Cmathbf%7BC%7D%5E%7Bi%20i%7D" style="display:inline-block;margin: 0;"/> 是系数矩阵的广义逆矩阵中第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 的随机效应对应的对角子矩阵；<img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 是第 <img src="https://math.now.sh?inline=i" style="display:inline-block;margin: 0;"/> 个随机效应的预测值。</p>
<p>证明如下:</p>
<p>首先我们需要证明一个引理，因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%20%3D%20%5Cmathbf%7BZ%7D%5Cmathbf%7BG%7D%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%2B%5Cmathbf%7BR%7D" style="display:inline-block;margin: 0;"/> ，如果我们将 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D%20%3D%20%20%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/>  中设置 <img src="https://math.now.sh?inline=%5Cmathbf%7BZ%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，将新的式子定义为 <img src="https://math.now.sh?inline=%5Cmathbf%7BS%7D" style="display:inline-block;margin: 0;"/> ，得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BS%7D%20%3D%20%20%5Cmathbf%7BR%7D%5E%7B-1%7D-%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%0A" /></p><p>那么我们有下面的引理。</p>
<p><strong>引理</strong>：</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BP%7D%3D%5Cmathbf%7BS-S%20Z%5Cleft%28D%5E%7B-1%7D%2BZ%5E%7B%5Cprime%7D%20S%20Z%5Cright%29%5E%7B-1%7D%20Z%5E%7B%5Cprime%7D%20S%7D%0A" /></p><p>证明：因为我们有 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D%20%3D%20%5Cmathbf%7BK%7D%20%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%20K%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> ，代入  <img src="https://math.now.sh?inline=%5Cmathbf%7BZ%7D%3D%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> 得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BS%7D%20%3D%20%5Cmathbf%7BK%7D%20%5Cleft%28%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%20K%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%0A" /></p><p>因此我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BP%7D%3D%20%26%20%5Cmathbf%7BK%7D%5Cleft%5B%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%28%5Cmathbf%7BZ%20G%20Z%5E%7B%5Cprime%7D%7D%2B%5Cmathbf%7BR%7D%29%20%5Cmathbf%7BK%7D%5Cright%5D%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%3D%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%20K%7D%2B%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BZ%20G%20Z%5E%7B%5Cprime%7D%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5C%5C%0A%3D%20%26%20%5Cmathbf%7BK%7D%5Cleft%5C%7B%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%20K%7D%5Cright)%5E%7B-1%7D-%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%20K%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BZ%20G%7D%5Cleft%5B%5Cmathbf%7BI%7D%2B%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%20K%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BZ%20G%7D%5Cright%5D%5E%7B-1%7D%5Cright.%20%5C%5C%0A%26%20%5Cleft.%5Ctimes%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%20K%7D%5Cright)%5E%7B-1%7D%5Cright%5C%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%2C%20%5Ctext%20%7B%20%E4%BD%BF%E7%94%A8%E7%AC%AC%E4%BA%8C%E4%B8%AA%E8%88%92%E5%B0%94%E8%A1%A5%E5%85%AC%E5%BC%8F%20%7D%5C%5C%0A%3D%20%26%20%5Cmathbf%7BS%7D-%5Cmathbf%7BS%20Z%20G%7D%5Cleft(%5Cmathbf%7BI%7D%2B%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BS%20Z%20G%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BS%7D%20%5C%5C%0A%3D%20%26%20%5Cmathbf%7BS%7D-%5Cmathbf%7BS%20Z%7D%5Cleft(%5Cmathbf%7BG%7D%5E%7B-1%7D%2B%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BS%20Z%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BS%7D%20.%0A%5Cend%7Baligned%7D%0A" /></p><p>注意这个公式和 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 有着相似的格式，只是其中的 <img src="https://math.now.sh?inline=%5Cmathbf%7BR%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 替换成了 <img src="https://math.now.sh?inline=%5Cmathbf%7BS%7D" style="display:inline-block;margin: 0;"/></p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BV%7D%5E%7B-1%7D%20%3D%20%5Cmathbf%7BR%7D%5E%7B-1%7D-%5Cmathbf%7BR%5E%7B-1%7D%20Z%7D%5Cleft%28%5Cmathbf%7BG%7D%5E%7B-1%7D%2B%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%5E%7B-1%7D%20Z%7D%5Cright%29%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%0A" /></p><p>舒尔补公式说明如下，如果一个非奇异分块矩阵中，如果 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 可逆，则其逆矩阵可以表示为</p>
<p style=""><img src="https://math.now.sh?from=%5Cleft%5B%5Cbegin%7Barray%7D%7Bll%7D%0A%5Cmathbf%7BA%7D%20%26%20%5Cmathbf%7BB%7D%20%5C%5C%0A%5Cmathbf%7BC%7D%20%26%20%5Cmathbf%7BD%7D%0A%5Cend%7Barray%7D%5Cright%5D%5E%7B-1%7D%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20%26%20%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7B0%7D%0A%5Cend%7Barray%7D%5Cright%5D%2B%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A-%5Cmathbf%7BA%7D%5E%7B-1%7D%20%5Cmathbf%7BB%7D%20%5C%5C%0A%5Cmathbf%7BI%7D%0A%5Cend%7Barray%7D%5Cright%5D%5Cleft%28%5Cmathbf%7BD%7D-%5Cmathbf%7BC%20A%7D%5E%7B-1%7D%20%5Cmathbf%7BB%7D%5Cright%29%5E%7B-1%7D%5Cleft%5B-%5Cmathbf%7BC%20A%7D%5E%7B-1%7D%20%5Cquad%20%5Cmathbf%7BI%7D%5Cright%5D%0A" /></p><p>其中矩阵 <img src="https://math.now.sh?inline=%5Cmathbf%7BD%7D-%5Cmathbf%7BC%20A%7D%5E%7B-1%7D%20%5Cmathbf%7BB%7D" style="display:inline-block;margin: 0;"/> 称为 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 的舒尔补，Marsaglia 和 Styan (1974a,b) 给出了两个重要公式，分别为（第二个式子可以理解为将 <img src="https://math.now.sh?inline=%5Cmathbf%7BA%7D" style="display:inline-block;margin: 0;"/> 替换成了  <img src="https://math.now.sh?inline=%5Cmathbf%7B-A%7D" style="display:inline-block;margin: 0;"/> ）。</p>
<p style=""><img src="https://math.now.sh?from=%5Cleft%28%5Cmathbf%7BD%7D-%5Cmathbf%7BC%20A%7D%5E%7B-1%7D%20%5Cmathbf%7BB%7D%5Cright%29%5E%7B-1%7D%3D%5Cmathbf%7BD%7D%5E%7B-1%7D%2B%5Cmathbf%7BD%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5Cleft(%5Cmathbf%7BA%7D-%5Cmathbf%7BB%20D%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BB%20D%7D%5E%7B-1%7D%2C%0A" /></p><p style=""><img src="https://math.now.sh?from=%5Cleft%28%5Cmathbf%7BD%7D%2B%5Cmathbf%7BC%20A%7D%5E%7B-1%7D%20%5Cmathbf%7BB%7D%5Cright%29%5E%7B-1%7D%3D%5Cmathbf%7BD%7D%5E%7B-1%7D-%5Cmathbf%7BD%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5Cleft(%5Cmathbf%7BA%7D%2B%5Cmathbf%7BB%20D%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BB%20D%7D%5E%7B-1%7D%20%5Ctext%20%7B%2C%20%7D%0A" /></p><p>我们再看公式 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%29%3D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%20%5Cmathbf%7BV%7D_%7Bi%7D%20%5Cmathbf%7BP%7D%20%7B%5Cmathbf%7By%7D%7D" style="display:inline-block;margin: 0;"/> 的左手项 <img src="https://math.now.sh?inline=%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BP%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%29" style="display:inline-block;margin: 0;"/> ，之前在 ML 的 EM 算法推导中，我们得到</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright%29%3D%5Cleft%5Bq_i-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BW%7D_%7Bii%7D%5Cright)%5Cright%5D%20%2F%20%5Csigma_i%5E2%0A" /></p><p>这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D_%7Bii%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D%3D%5Cleft%28%5Cmathbf%7BI%7D%2B%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BR%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%5Cright%29%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 的第 <img src="https://math.now.sh?inline=%28i%2Ci%29" style="display:inline-block;margin: 0;"/> 个子矩阵。</p>
<p>因为 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D" style="display:inline-block;margin: 0;"/> 和  <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 的差别就是将 <img src="https://math.now.sh?inline=%5Cmathbf%7BR%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 替换成了 <img src="https://math.now.sh?inline=%5Cmathbf%7BS%7D" style="display:inline-block;margin: 0;"/>， 因此我们得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Btr%7D%5Cleft%28%5Cmathbf%7BP%20Z%7D_i%20%5Cmathbf%7BZ%7D_i%5E%7B%5Cprime%7D%5Cright%29%3D%5Cleft%5Bq_i-%5Coperatorname%7Btr%7D%5Cleft(%5Cmathbf%7BT%7D_%7Bii%7D%5Cright)%5Cright%5D%20%2F%20%5Csigma_i%5E2%0A" /></p><p>这里 <img src="https://math.now.sh?inline=%5Cmathbf%7BT%7D_%7Bii%7D" style="display:inline-block;margin: 0;"/> 是 <img src="https://math.now.sh?inline=%5Cmathbf%7BW%7D" style="display:inline-block;margin: 0;"/> 中将 <img src="https://math.now.sh?inline=%5Cmathbf%7BR%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 替换成了 <img src="https://math.now.sh?inline=%5Cmathbf%7BS%7D" style="display:inline-block;margin: 0;"/> 的子矩阵，我们标记为</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BT%7D%3D%5Cleft%28%5Cmathbf%7BI%7D%2B%5Cmathbf%7BZ%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BS%7D%20%5Cmathbf%7BZ%7D%20%5Cmathbf%7BG%7D%5Cright%29%5E%7B-1%7D%0A" /></p><p>因为 REML 公式和 ML 公式的右手项不变，因此我们得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%2B%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BT%7D_%7Bii%7D%5Cright%29%20%7D%20%7Bq_%7Bi%7D%7D%0A" /></p><p>或者</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%3D%5Cfrac%7B%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%20%5Chat%7B%5Cmathbf%7Bu%7D%7D_%7Bi%7D%7D%7Bq_%7Bi%7D-%20%5Coperatorname%7Btr%7D%20%5Cleft%28%5Cmathbf%7BT%7D_%7Bii%7D%5Cright%29%20%7D%0A" /></p><p>通过上面这两个公式我们得到了 REML 的 EM 算法。在计算时，我们先给出一组初始的 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值，由混合模型方程组求出相应的 <img src="https://math.now.sh?inline=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D" style="display:inline-block;margin: 0;"/>  和 <img src="https://math.now.sh?inline=%5Chat%7B%5Cmathbf%7Bu%7D%7D" style="display:inline-block;margin: 0;"/> ，以及相应的系数矩阵逆矩阵元素；再由上面的两个公式求出一组新的  <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值，如此迭代下去，知道两次迭代得到的   <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 值得差异小于给定阈值时，迭代收敛。</p>
<p>而且根据上面两个公式，可以得到 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 都比大于0，因此 EM 算法一定满足参数空间的要求。</p>
<h1>EM 算法</h1>
<p>EM 算法的全名为 expectation-maximization ，因为它在计算条件期望值和最大化简化的似然函数值间不断跳转。<strong>EM算法只会计算估计值，而不会计算估计值的方差</strong>。</p>
<p>EM 算法用于当数据增加时会简化问题难度的最大似然估计，应用 EM 算法的核心在于决定什么是完整数据（观测数据+未观测到的数据）。实际数据（观测数据）在 EM 算法中一般称为不完整的数据。因此在方差组分估计中，我们将表型 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 视为不完整的数据，完整数据为表型 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 加上未观测的随机效应 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> (<img src="https://math.now.sh?inline=i%3D1%2C2%2C%5Ccdots%2Cr" style="display:inline-block;margin: 0;"/>) 。</p>
<p>如果我们知道随机效应 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 的值，我们可以用其平方和均值估计随机效应的方差，该式为基于完整数据的最大似然估计值。</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%3D%20%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%2Fq_%7Bi%7D%0A" /></p><p>但是，实际上我们并不知道随机效应 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 的值，但是 EM 算法给了我们一种基于 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 估计 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 的方法。首先我们采用一组参数的初始值，我们之后基于  <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 计算 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 的条件期望（E 步, expectation step），然后利用其条件期望值使用<strong>最大似然法</strong>得到一组新的参数估计值（M 步， maximization step）。然后不断循环这两步直到收敛。</p>
<p>EM 算法的一个重要特征是，因为 EM 算法对完整数据执行最大似然估计，因此每一次迭代得到的估计值均在参数空间中。</p>
<h2 id="联合分布">联合分布</h2>
<p>因为我们需要计算给定  <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 条件下 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 的条件期望，因此我们需要 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D%20%3D%20%5Cleft%5B%20%5Cmathbf%7Bu%7D_%7B1%7D%5E%7B%5Cprime%7D%2C%20%5Cmathbf%7Bu%7D_%7B2%7D%5E%7B%5Cprime%7D%2C%20%5Ccdots%2C%20%5Cmathbf%7Bu%7D_%7Br%7D%5E%7B%5Cprime%7D%20%5Cright%5D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> 的联合分布。</p>
<p>我们有下面的式子</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7By%7D%20%26%3D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%20%2B%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D%20%2B%20%5Cmathbf%7Be%7D%20%5C%5C%0A%26%3D%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%20%2B%20%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>其中 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7B0%7D%20%3D%20%5Cmathbf%7Be%7D" style="display:inline-block;margin: 0;"/> , <img src="https://math.now.sh?inline=q_%7B0%7D%20%3D%20N" style="display:inline-block;margin: 0;"/> , <img src="https://math.now.sh?inline=%5Cmathbf%7BZ%7D_%7B0%7D%20%3D%20%5Cmathbf%7BI%7D_%7Bn%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Coperatorname%7Bcov%7D%28%5Cmathbf%7By%7D%2C%20%5Cmathbf%7Bu%7D_%7Bj%7D%5E%7B%5Cprime%7D%29%20%3D%20%5Coperatorname%7Bcov%7D%20%5Cleft(%20%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%20%2B%20%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D%2C%20%5Cmathbf%7Bu%7D_%7Bj%7D%5E%7B%5Cprime%7D%20%5Cright)%20%3D%20%5Cmathbf%7BZ%7D_%7Bj%7D%20%5Coperatorname%7Bcov%7D%20(%5Cmathbf%7Bu%7D_%7Bj%7D%2C%20%5Cmathbf%7Bu%7D_%7Bj%7D%5E%7B%5Cprime%7D)%20%3D%20%5Csigma_%7Bj%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bj%7D%0A" /></p><p>同时我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BV%7D%20%3D%20%5Coperatorname%7Bcov%7D%20%28%5Cmathbf%7By%7D%29%20%3D%20%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%2B%20%5Csigma_%7B0%7D%5E%7B2%7D%20%5Cmathbf%7BI%7D_%7BN%7D%0A" /></p><p>因此 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D" style="display:inline-block;margin: 0;"/> 的联合分布为 <img src="https://math.now.sh?inline=N%28%5Cboldsymbol%7B%5Cmu%7D%2C%20%5Cboldsymbol%7B%5CSigma%7D%29" style="display:inline-block;margin: 0;"/> ，其中</p>
<p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7B%5Cmu%7D%20%3D%5Cleft%5B%20%5Cbegin%7Barray%7D%20%7Bc%7D%0A%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cvdots%20%5C%5C%0A%5Cmathbf%7B0%7D%5C%5C%0A%20%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7B%5CSigma%7D%20%3D%5Cleft%5B%20%5Cbegin%7Barray%7D%20%7Bcc%7D%0A%5Cmathbf%7BV%7D%20%26%20%5Cleft%5C%7B_%7Br%7D%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%20%5C%5C%0A%20%5Cleft%5C%7B_%7Bc%7D%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%20%26%20%20%5Cleft%5C%7B_%7Bd%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%5C%5C%0A%20%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p>因此我们有概率密度函数</p>
<p style=""><img src="https://math.now.sh?from=f_%7B%5Cmathbf%7By%7D%2C%20%5Cboldsymbol%7B%5Cmu%7D%7D%28%5Cmathbf%7By%7D%2C%20%5Cboldsymbol%7B%5Cmu%7D%29%3D%20(2%5Cpi)%5E%7B-%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi%3D0%7D%5E%7Br%7Dq_%7Bi%7D%7D%20%20%7C%5Cmathbf%7B%5CSigma%7D%7C%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D%20%5Cexp%20%5Cleft%5C%7B-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7BQ%7D%20%5Cright%5C%7D%0A" /></p><p>其中</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BQ%7D%20%3D%20%5Cleft%5B%20%28%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D%29%5E%7B%5Cprime%7D%20%5Cquad%20%5Cmathbf%7Bu%7D_%7B1%7D%5E%7B%5Cprime%7D%20%5Cquad%20%5Cmathbf%7Bu%7D_%7B2%7D%5E%7B%5Cprime%7D%20%5Cquad%20%5Ccdots%20%5Cquad%20%5Cquad%20%5Cmathbf%7Bu%7D_%7Br%7D%5E%7B%5Cprime%7D%20%5Cright%5D%20%5Cmathbf%7B%5CSigma%7D%5E%7B-1%7D%20%20%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D)%20%5C%5C%0A%5Cmathbf%7Bu%7D_%7B1%7D%20%5C%5C%0A%5Cmathbf%7Bu%7D_%7B2%7D%20%5C%5C%0A%5Cvdots%20%5C%5C%0A%5Cmathbf%7Bu%7D_%7Br%7D%20%5Cend%7Barray%7D%20%5Cright%5D%0A" /></p><p>根据舒尔补，我们有公式</p>
<p style=""><img src="https://math.now.sh?from=%5Cleft%7C%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7BA%7D%20%26%20%5Cmathbf%7BB%7D%5C%5C%0A%5Cmathbf%7BC%7D%20%26%20%5Cmathbf%7BD%7D%5C%5C%0A%0A%5Cend%7Barray%7D%20%5Cright%7C%20%3D%20%7C%5Cmathbf%7BD%7D%7C%5Cmathbf%7BA-BD%5E%7B-1%7DC%7D%7C%0A" /></p><p>我们推导得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%7C%5Cmathbf%7B%5CSigma%7D%7C%20%26%3D%20%7C%5Cleft%5C%7B_%7Bd%7D%20%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%7C%5Cmathbf%7BV%7D%20-%20%5Cleft%5C%7B_%7Br%7D%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%20%5Cleft%5C%7B_%7Bd%7D%20%28%5Csigma_%7Bi%7D%5E%7B2%7D%29%5E%7B-1%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%20%5Cleft%5C%7B_%7Bc%7D%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%5C%7D_%7Bi%3D1%7D%5E%7Br%7D%20%7C%20%5C%5C%0A%26%3D%5Cprod_%7Bi%3D1%7D%5E%7Br%7D(%5Csigma_%7Bi%7D%5E%7B2%7D)%5E%7Bq_%7Bi%7D%7D%20%7C%5Cmathbf%7BV%7D%20-%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%7C%20%5C%5C%0A%26%3D%5Cprod_%7Bi%3D1%7D%5E%7Br%7D(%5Csigma_%7Bi%7D%5E%7B2%7D)%5E%7Bq_%7Bi%7D%7D%20%7C%5Csigma_%7B0%7D%5E%7B2%7D%5Cmathbf%7BI%7D_%7BN%7D%7C%20%5C%5C%0A%26%3D%5Cprod_%7Bi%3D1%7D%5E%7Br%7D(%5Csigma_%7Bi%7D%5E%7B2%7D)%5E%7Bq_%7Bi%7D%7D%20(%5Csigma_%7B0%7D%5E%7B2%7D)%5E%7BN%7D%20%5C%5C%0A%26%3D%5Cprod_%7Bi%3D0%7D%5E%7Br%7D(%5Csigma_%7Bi%7D%5E%7B2%7D)%5E%7Bq_%7Bi%7D%7D%20%5C%5C%0A%0A%0A%5Cend%7Baligned%7D%0A" /></p><p>同时根据舒尔补公式</p>
<p style=""><img src="https://math.now.sh?from=%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7BA%7D%20%26%20%5Cmathbf%7BB%7D%20%5C%5C%0A%5Cmathbf%7BC%7D%20%26%20%5Cmathbf%7BD%7D%20%5C%5C%0A%5Cend%7Barray%7D%5Cright%5D%5E%7B-1%7D%20%3D%20%20%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7BD%7D%5E%7B-1%7D%20%5C%5C%0A%5Cend%7Barray%7D%5Cright%5D%20%2B%20%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7BI%7D%20%5C%5C%0A-%5Cmathbf%7BD%7D%5E%7B-1%7D%5Cmathbf%7BC%7D%20%5C%5C%0A%5Cend%7Barray%7D%5Cright%5D%28%5Cmathbf%7BA%7D-%5Cmathbf%7BB%20D%7D%5E%7B-1%7D%20%5Cmathbf%7BC%7D%29%5E%7B-1%7D%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7BI%7D%20%26%20%5Cmathbf%7B-BD%5E%7B-1%7D%7D%5C%5C%0A%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p>我们得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7B%5CSigma%7D%5E%7B-1%7D%20%3D%20%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7B0%7D%20%26%20%5Cmathbf%7B0%7D%20%5C%5C%0A%5Cmathbf%7B0%7D%20%26%20%20%5Cleft%5C%7B_%7Bd%7D%20%5Csigma_%7Bi%7D%5E%7B-2%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20%5Cright%5C%7D%20%5C%5C%0A%5Cend%7Barray%7D%5Cright%5D%20%2B%20%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7BI%7D%20%5C%5C%0A-%5Cleft%5C%7B_%7Bc%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cright%5C%7D%20%5C%5C%0A%5Cend%7Barray%7D%5Cright%5D%20%5Csigma_%7B0%7D%5E%7B-2%7D%5Cmathbf%7BI%7D_%7BN%7D%20%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cmathbf%7BI%7D%20%26%20-%5Cleft%5C%7B_%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cright%5C%7D%5C%5C%0A%5Cend%7Barray%7D%5Cright%5D%0A" /></p><p>因此</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BQ%7D%20%26%3D%20%5Cleft%5B%20%28%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D%29%5E%7B%5Cprime%7D%20%5Cquad%20%5Cmathbf%7Bu%7D%5E%7B%5Cprime%7D%20%20%5Cright%5D%20%5Cmathbf%7B%5CSigma%7D%5E%7B-1%7D%20%20%5Cleft%5B%5Cbegin%7Barray%7D%7Bc%7D%0A(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D)%20%5C%5C%0A%5Cmathbf%7Bu%7D%20%5C%5C%20%5Cend%7Barray%7D%20%5Cright%5D%20%5C%5C%0A%26%3D%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cfrac%7B%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7D%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%2B%20%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%2F%5Csigma_%7B0%7D%5E%7B2%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>因此，将上面的式子代入基于完全数据的对数似然函数（概率密度函数），得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0Al%20%26%20%3D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%28%20%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20q_%7Bi%7D%20%5Cright%29%20%5Cln%202%20%5Cpi-%20%5Cfrac%7B1%7D%7B2%7D%20%20%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20q_%7Bi%7D%20%5Cln%20%5Csigma_%7Bi%7D%5E%7B2%7D%20-%20%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cfrac%7B%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7D%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5C%5C%0A%0A%26%20%5Cquad%20-%20%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%2F%5Csigma_%7B0%7D%5E%7B2%7D%20%5C%5C%0A%26%20%3D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(%20%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20q_%7Bi%7D%20%5Cright)%20%5Cln%202%20%5Cpi-%20%5Cfrac%7B1%7D%7B2%7D%20%20%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20q_%7Bi%7D%20%5Cln%20%5Csigma_%7Bi%7D%5E%7B2%7D%20-%20%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D0%7D%5E%7Br%7D%20%5Cfrac%7B%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7D%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%5C%5C%0A%0A%5Cend%7Baligned%7D%0A" /></p><p>其中第二步推导是因为 <img src="https://math.now.sh?inline=%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D%20%3D%20%5Cmathbf%7Be%7D%20%3D%20%5Cmathbf%7Bu%7D_%7B0%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>因此根据完全数据的对数似然函数，对 <img src="https://math.now.sh?inline=%5Csigma_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> 求偏导，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20l%7D%7B%5Cpartial%20%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20%3D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%28%20%5Cfrac%7Bq_%7Bi%7D%7D%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D%20-%20%5Cfrac%7B%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7D%7B%5Csigma_%7Bi%7D%5E%7B4%7D%7D%20%5Cright%29%0A" /></p><p>使该式为 0 ，我们可以轻松得到 ML 估计值</p>
<p style=""><img src="https://math.now.sh?from=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%3D%20%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%2Fq_%7Bi%7D%0A" /></p><p>对 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cbeta%7D" style="display:inline-block;margin: 0;"/> 求偏导，计算过程如下</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Cmathrm%7Bd%7D%28%5Cmathrm%7Btr%7D((%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D%29%5E%7B%5Cprime%7D%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)))%20%5C%5C%0A%26%3D%5Cmathrm%7Btr%7D(%5Cmathrm%7Bd%7D((%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)))%20%5C%5C%0A%26%3D%5Cmathrm%7Btr%7D%5Cleft(-%5Cmathrm%7Bd%7D(%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%5Cprime%7D%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D)%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)-(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%5Cmathrm%7Bd%7D(%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D)%20%20%5Cright)%20%5C%5C%0A%26%3D-%5Cmathrm%7Btr%7D%5Cleft(%5Cmathrm%7Bd%7D(%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%5Cprime%7D)%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20(%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5Cright)-%5Cmathrm%7Btr%7D%5Cleft((%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%5Cmathbf%7BX%7D%5Cmathrm%7Bd%7D(%20%5Cboldsymbol%7B%5Cbeta%7D)%20%20%5Cright)%20%5C%5C%0A%26%3D-%5Cmathrm%7Btr%7D%5Cleft((%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%5Cmathbf%7BX%7D%5Cmathrm%7Bd%7D(%20%5Cboldsymbol%7B%5Cbeta%7D)%20%20%5Cright)-%5Cmathrm%7Btr%7D%5Cleft((%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%5Cmathbf%7BX%7D%5Cmathrm%7Bd%7D(%20%5Cboldsymbol%7B%5Cbeta%7D)%20%20%5Cright)%20%5C%5C%0A%26%3D-2%5Cmathrm%7Btr%7D%5Cleft((%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D)%5E%7B%5Cprime%7D%5Cmathbf%7BX%7D%5Cmathrm%7Bd%7D(%20%5Cboldsymbol%7B%5Cbeta%7D)%20%20%5Cright)%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>因此</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20l%7D%7B%5Cpartial%20%5Cboldsymbol%7B%5Cbeta%7D%7D%20%3D%20%5Cfrac%7B1%7D%7B%5Csigma_%7B0%7D%5E%7B2%7D%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%28%5Cmathbf%7By-X%7D%5Cboldsymbol%7B%5Cbeta%7D-%5Csum_%7Bi%3D1%7D%5E%7Br%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7Bu%7D_%7Bi%7D%29%0A" /></p><p>使之为 <img src="https://math.now.sh?inline=%5Cmathbf%7B0%7D" style="display:inline-block;margin: 0;"/> ，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%20%3D%20%5Cmathbf%7B%28X'X%29%5E%7B-%7DX'%7D%5Cleft(%20%5Cmathbf%7By%7D%20-%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D%20%20%5Cright)%0A" /></p><p>即</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%20%3D%20%5Cmathbf%7BX%28X'X%29%5E%7B-%7DX'%7D%5Cleft(%20%5Cmathbf%7By%7D%20-%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D%20%20%5Cright)%0A" /></p><p>这个公式等价于从 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 中剔除除了残差之外的随机效应，再应用普通最小二乘法得到的估计值。</p>
<p>为了完善 EM 算法的迭代步骤，我们还需要知道 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D%20-%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 在给定 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 时的条件期望。我们可以直接使用多变量正态分布的公式</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0AE%28%5Cmathbf%7By%7D%20%5Cmid%20%5Cmathbf%7Bx%7D%29%20%26%3D%5Cboldsymbol%7B%5Cmu%7D_%7By%7D%2B%5Cmathbf%7B%5CSigma%7D_%7By%20x%7D%20%5CSigma_%7Bx%20x%7D%5E%7B-1%7D%5Cleft(%5Cmathbf%7Bx%7D-%5Cboldsymbol%7B%5Cmu%7D_%7Bx%7D%5Cright)%2C%20%5C%5C%0A%5Coperatorname%7Bcov%7D(%5Cmathbf%7By%7D%20%5Cmid%20%5Cmathbf%7Bx%7D)%20%26%3D%5Cmathbf%7B%5CSigma%7D_%7By%20y%7D-%5Cmathbf%7B%5CSigma%7D_%7By%20x%7D%20%5Cmathbf%7B%5CSigma%7D_%7Bx%20x%7D%5E%7B-1%7D%20%5Cmathbf%7B%5CSigma%7D_%7Bx%20y%7D%20.%0A%5Cend%7Baligned%7D%0A" /></p><p>进行推导得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7Bu%7D_%7Bi%7D%20%7C%20%5Cmathbf%7By%7D%20%5Csim%20%5Cmathcal%7BN%7D%5Cleft%5B%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%28%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%29%2C%20%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20-%20%5Csigma_%7Bi%7D%5E%7B4%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cright%5D%0A" /></p><p>因此我们得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathrm%7BE%7D%28%5Cmathbf%7Bu%7D_%7Bi%7D%20%7C%20%5Cmathbf%7By%7D%29%20%3D%20%5Csigma_%7Bi%7D%5E%7B2%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D)%0A" /></p><p>根据二次型期望公式 <img src="https://math.now.sh?inline=%5Cmathrm%7BE%7D%5Cleft%28%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%20y%7D%5Cright%29%3D%5Coperatorname%7Btr%7D(%5Cmathbf%7BA%7D%20%5CSigma)%2B%5Cboldsymbol%7B%5Cmu%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BA%7D%20%5Cboldsymbol%7B%5Cmu%7D" style="display:inline-block;margin: 0;"/> ，我们可以推导得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathrm%7BE%7D%28%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7C%5Cmathbf%7By%7D%29%20%3D%20%5Csigma_%7Bi%7D%5E%7B4%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D)%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D)%20%2B%20%5Cmathrm%7Btr%7D(%5Csigma_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20-%20%5Csigma_%7Bi%7D%5E%7B4%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D)%0A" /></p><h2 id="ML-的-EM-算法1">ML 的 EM 算法1</h2>
<p>我们现在可以形成 ML 的 EM 算法的正式描述，其中上标 <img src="https://math.now.sh?inline=m" style="display:inline-block;margin: 0;"/> 为第 m 次迭代得到的估计值</p>
<p><strong>step 0</strong>:  给定一组初始值 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%280%29%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Csigma%7D%5E%7B2%280%29%7D" style="display:inline-block;margin: 0;"/> ，<img src="https://math.now.sh?inline=m%3D0" style="display:inline-block;margin: 0;"/>  。</p>
<p><strong>step 1 (E 步)</strong>: 计算 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7By%7D%20-%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 这两个统计量的条件期望，将它们标记为 <img src="https://math.now.sh?inline=t_%7Bi%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7Bs%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Chat%7Bt%7D_%7Bi%7D%5E%7B%28m%29%7D%20%26%3D%20%5Cmathrm%7BE%7D(%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7C%5Cmathbf%7By%7D)%7C_%7B%5Cboldsymbol%7B%5Cbeta%7D%3D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D%2C%20%5Cmathbf%7B%5Csigma%7D%5E%7B2%7D%3D%5Cmathbf%7B%5Csigma%7D%5E%7B2(m)%7D%7D%20%5C%5C%0A%26%3D%5Csigma_%7Bi%7D%5E%7B4(m)%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D)%5E%7B%5Cprime%7D(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D)%20%5C%5C%0A%26%20%5Cquad%20%2B%20%5Cmathrm%7Btr%7D(%5Csigma_%7Bi%7D%5E%7B2(m)%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20-%20%5Csigma_%7Bi%7D%5E%7B4(m)%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7B%5Chat%7Bs%7D%7D%5E%7B%28m%29%7D%20%26%3D%20%5Cmathrm%7BE%7D(%5Cmathbf%7By%7D%20-%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%20%5Cmathbf%7Bu%7D_%7Bi%7D%7C%5Cmathbf%7By%7D)%7C_%7B%5Cboldsymbol%7B%5Cbeta%7D%3D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D%2C%20%5Cmathbf%7B%5Csigma%7D%5E%7B2%7D%3D%5Cmathbf%7B%5Csigma%7D%5E%7B2(m)%7D%7D%20%5C%5C%0A%26%3D%20%5Cmathbf%7By%7D%20-%20%5Csum_%7Bi%3D1%7D%5E%7Br%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Csigma_%7Bi%7D%5E%7B2(m)%7D%20(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D)%20%5C%5C%0A%26%3D%20%5Cmathbf%7By%7D%20-%20(%5Cmathbf%7BV%7D%5E%7B(m)%7D%20-%20%5Csigma_%7B0%7D%5E%7B2(m)%7D%5Cmathbf%7BI%7D)%20(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D)%20%5C%5C%0A%26%3D%20%5Cmathbf%7By%7D%20-%20(%5Cmathbf%7BV%7D%5E%7B(m)%7D%20-%20%5Csigma_%7B0%7D%5E%7B2(m)%7D%5Cmathbf%7BI%7D)%20(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D)%20%5C%5C%0A%26%3D%20%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D%2B%5Csigma_%7B0%7D%5E%7B2(m)%7D%20(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p><strong>step 2 (M 步)</strong>: 基于完整数据，采用最大似然法，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Csigma_%7Bi%7D%5E%7B2%28m%2B1%29%7D%20%3D%20%5Chat%7Bt%7D_%7Bi%7D%5E%7B(m)%7D%2Fq_%7Bi%7D%2C%20%5Cquad%20i%3D0%2C1%2C2%2C%5Ccdots%2Cr%0A" /></p><p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%5E%7B%28m%2B1%29%7D%7D%20%3D%20%5Cmathbf%7BX(X'X)%5E%7B-%7DX'%7D%5Cmathbf%7B%5Chat%7Bs%7D%7D_%7B(m)%7D%0A" /></p><p><strong>step 3</strong>: 如果达到了收敛标准，则将 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Csigma%7D%7D%5E%7B2%7D%20%3D%20%5Cboldsymbol%7B%5Csigma%7D%5E%7B2%28m%2B1%29%7D" style="display:inline-block;margin: 0;"/> ， <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%20%3D%20%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%28m%2B1%29%7D" style="display:inline-block;margin: 0;"/> ；不然 m 递增1，返回 step 1 。</p>
<h2 id="ML-的-EM-算法2">ML 的 EM 算法2</h2>
<p>如果我们使用 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D" style="display:inline-block;margin: 0;"/> 的 ML 估计值 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Chat%7BV%7D%7D" style="display:inline-block;margin: 0;"/> ，则 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D" style="display:inline-block;margin: 0;"/> 的 ML 估计值为  <img src="https://math.now.sh?inline=%5Cmathbf%7BX%28X'%5Chat%7BV%7D%5E%7B-1%7DX%29%5E%7B-%7DX'%5Chat%7BV%7D%5E%7B-1%7Dy%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>Laird (1992) 建议在 EM 算法的迭代过程中不计算 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Chat%7Bs%7D%7D%5E%7B%28m%29%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%28m%29%7D" style="display:inline-block;margin: 0;"/> ，而只是收敛时计算一次 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D" style="display:inline-block;margin: 0;"/> ，推导过程如下，如果上面式子中的 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%28m%29%7D" style="display:inline-block;margin: 0;"/> 均采用  <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D" style="display:inline-block;margin: 0;"/> 的公式计算，即</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%28m%29%7D_%7B*%7D%20%3D%20%5Cmathbf%7BX(X'(V%5E%7B(m)%7D)%5E%7B-1%7DX)%5E%7B-%7DX'(V%5E%7B(m)%7D)%5E%7B-1%7Dy%7D%0A" /></p><p>而在计算 <img src="https://math.now.sh?inline=%5Chat%7Bt%7D_%7Bi%7D%5E%7B%28m%29%7D" style="display:inline-block;margin: 0;"/> 其中用到了 <img src="https://math.now.sh?inline=%28%5Cmathbf%7BV%7D%5E%7B(m%29%7D)%5E%7B-1%7D(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D)" style="display:inline-block;margin: 0;"/> ，这正好是 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D%5E%7B%28m%29%7D%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> ，其中 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D%5E%7B%28m%29%7D" style="display:inline-block;margin: 0;"/> 为：</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BP%5E%7B%28m%29%7D%7D%20%3D%20(%5Cmathbf%7BV%5E%7B(m)%7D%7D)%5E%7B-1%7D%20-%20(%5Cmathbf%7BV%5E%7B(m)%7D%7D)%5E%7B-1%7D%20%5Cmathbf%7BX(X'(V%5E%7B(m)%7D)%5E%7B-1%7DX)%5E%7B-%7DX'(V%5E%7B(m)%7D)%5E%7B-1%7D%7D%0A" /></p><p>因此此时在每个迭代过程中，我们不需要得到 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%28m%29%7D" style="display:inline-block;margin: 0;"/> ，我们只需要计算  <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D%5E%7B%28m%29%7D%5Cmathbf%7By%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p>这个算法其实严格来说不是 EM 算法，但是和 EM 算法差距很小，具体过程如下：</p>
<p><strong>step 0</strong>:  给定一组初始 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Csigma%7D%5E%7B2%280%29%7D" style="display:inline-block;margin: 0;"/> ，<img src="https://math.now.sh?inline=m%3D0" style="display:inline-block;margin: 0;"/>  。</p>
<p><strong>step 1 (E 步)</strong>: 计算 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 的条件期望，标记为 <img src="https://math.now.sh?inline=t_%7Bi%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Chat%7Bt%7D_%7Bi%7D%5E%7B%28m%29%7D%20%26%3D%20%5Cmathrm%7BE%7D(%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7C%5Cmathbf%7By%7D)%7C_%7B%5Cboldsymbol%7B%5Cbeta%7D%3D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D%2C%20%5Cmathbf%7B%5Csigma%7D%5E%7B2%7D%3D%5Cmathbf%7B%5Csigma%7D%5E%7B2(m)%7D%7D%20%5C%5C%0A%26%3D%5Csigma_%7Bi%7D%5E%7B4(m)%7D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BP%7D%5E%7B(m)%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BP%7D%5E%7B(m)%7D%5Cmathbf%7By%7D%20%5C%5C%0A%26%20%5Cquad%20%2B%20%5Cmathrm%7Btr%7D(%5Csigma_%7Bi%7D%5E%7B2(m)%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20-%20%5Csigma_%7Bi%7D%5E%7B4(m)%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D(%5Cmathbf%7BV%7D%5E%7B(m)%7D)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p><strong>step 2 (M 步)</strong>: 基于完整数据，采用最大似然法，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Csigma_%7Bi%7D%5E%7B2%28m%2B1%29%7D%20%3D%20%5Chat%7Bt%7D_%7Bi%7D%5E%7B(m)%7D%2Fq_%7Bi%7D%2C%20%5Cquad%20i%3D0%2C1%2C2%2C%5Ccdots%2Cr%0A" /></p><p><strong>step 3</strong>: 如果达到了收敛标准，则将 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Csigma%7D%7D%5E%7B2%7D%20%3D%20%5Cboldsymbol%7B%5Csigma%7D%5E%7B2%28m%2B1%29%7D" style="display:inline-block;margin: 0;"/> ， <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%20%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%20%3D%20%5Cmathbf%7BX%28X'%5Chat%7BV%7D%5E%7B-1%7DX%29%5E%7B-%7DX'%5Chat%7BV%7D%5E%7B-1%7Dy%7D" style="display:inline-block;margin: 0;"/> ；不然 m 递增1，返回 step 1 。</p>
<h2 id="EM-算法和-ML-方程组的等价性">EM 算法和 ML 方程组的等价性</h2>
<p>我们现在考虑EM 算法和 ML 方程组的等价性，首先当 EM 算法收敛时，我们有 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%3D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B%28m%2B1%29%7D%3D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D" style="display:inline-block;margin: 0;"/>， <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Csigma%7D%5E%7B2%7D%7D%3D%5Cboldsymbol%7B%5Csigma%7D%5E%7B2%28m%2B1%29%7D%3D%5Cboldsymbol%7B%5Csigma%7D%5E%7B2(m)%7D" style="display:inline-block;margin: 0;"/> ，利用第一个等式，根据 ML 的 EM 算法1， 我们得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%20%3D%20%5Cmathbf%7BX%28X'X%29%5E%7B-%7DX'%7D%5Cleft%5B%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%2B%5Chat%7B%5Csigma%7D_%7B0%7D%5E%7B2%7D%20(%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D%20(%5Cmathbf%7By%7D-%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D)%20%5Cright%5D%0A" /></p><p>根据广义逆性质我们有 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%20%3D%20%5Cmathbf%7BX%28X'X%29%5E%7B-%7DX'X%7D" style="display:inline-block;margin: 0;"/> ，因此化简得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BX%28X'X%29%5E%7B-%7DX'%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%20%3D%20%5Cmathbf%7BX(X'X)%5E%7B-%7DX'%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D%5Cmathbf%7By%7D%0A" /></p><p>等式左右两侧乘以 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D" style="display:inline-block;margin: 0;"/> , 根据广义逆性质 <img src="https://math.now.sh?inline=%5Cmathbf%7BX'%7D%20%3D%20%5Cmathbf%7BX'X%28X'X%29%5E%7B-%7DX'%7D" style="display:inline-block;margin: 0;"/>, 我们得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BX'%7D%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D%5Cmathbf%7BX%7D%5Cboldsymbol%7B%5Chat%7B%5Cbeta%7D%7D%20%3D%20%5Cmathbf%7BX'%7D%20%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D%5Cmathbf%7By%7D%0A" /></p><p>这就是 ML 方程组中的一个式子。</p>
<p>类似地，对于 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D" style="display:inline-block;margin: 0;"/> ，我们有</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0Aq_%7Bi%7D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%26%3D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B4%7D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7B%5Chat%7BP%7D%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7B%5Chat%7BP%7D%7D%5Cmathbf%7By%7D%0A%20%2B%20%5Cmathrm%7Btr%7D%28%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20-%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B4%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D(%5Cmathbf%7B%5Chat%7BV%7D%7D%29%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D)%20%5C%5C%0A%20%26%3D%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B4%7D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7B%5Chat%7BP%7D%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7B%5Chat%7BP%7D%7D%5Cmathbf%7By%7D%0A%20%2B%20q_%7Bi%7D%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20-%20%20%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B4%7D%20%5Cmathrm%7Btr%7D(%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D(%5Cmathbf%7B%5Chat%7BV%7D%7D)%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D)%20%5C%5C%0A%20%5Cend%7Baligned%7D%0A" /></p><p>只要 <img src="https://math.now.sh?inline=%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D%20%5Cneq%200" style="display:inline-block;margin: 0;"/> ，我们可以简单得到</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathrm%7Btr%7D%28%20%5Cmathbf%7B%5Chat%7BV%7D%7D%5E%7B-1%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%29%20%3D%20%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7B%5Chat%7BP%7D%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7B%5Chat%7BP%7D%7D%5Cmathbf%7By%7D%0A" /></p><p>这是 ML 方程组中的另外一个式子。</p>
<h2 id="REML-的-EM-算法">REML 的 EM 算法</h2>
<p>我们只需要将 ML 的 EM 算法中的矩阵和向量进行以下替换：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%5Ctext%7Breplacing%7D%20%5Cquad%20%5Cmathbf%7By%7D%20%5Cquad%20%5Ctext%7Bby%7D%20%5Cquad%20%5Cmathbf%7BK'y%7D%20%5C%5C%0A%26%5Ctext%7Breplacing%7D%20%5Cquad%20%5Cmathbf%7BX%7D%20%5Cquad%20%5Ctext%7Bby%7D%20%5Cquad%20%5Cmathbf%7BK'X%3D0%7D%20%5C%5C%0A%26%5Ctext%7Breplacing%7D%20%5Cquad%20%5Cmathbf%7BZ%7D%20%5Cquad%20%5Ctext%7Bby%7D%20%5Cquad%20%5Cmathbf%7BK'Z%7D%20%5C%5C%0A%26%5Ctext%7Breplacing%7D%20%5Cquad%20%5Cmathbf%7BV%7D%20%5Cquad%20%5Ctext%7Bby%7D%20%5Cquad%20%5Cmathbf%7BK'VK%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p>然后我们就可以从  ML 的 EM 算法2 推导得到 REML 的 EM 算法。</p>
<p>其中会应用到下面的式子</p>
<p style=""><img src="https://math.now.sh?from=%5Cmathbf%7BP%7D%3D%5Cmathbf%7BV%7D%5E%7B-1%7D-%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cleft%28%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%20%5Cmathbf%7BX%7D%5Cright%29%5E%7B-%7D%20%5Cmathbf%7BX%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%5E%7B-1%7D%3D%5Cmathbf%7BK%7D%5Cleft(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BV%7D%20%5Cmathbf%7BK%7D%5Cright)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%0A" /></p><p>我们先推导一下ML 的 EM 算法2式子中的 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D" style="display:inline-block;margin: 0;"/> 矩阵，将其中的 <img src="https://math.now.sh?inline=%5Cmathbf%7BX%7D" style="display:inline-block;margin: 0;"/> 和 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D" style="display:inline-block;margin: 0;"/> 矩阵进行替换，得到：</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cmathbf%7BP%7D%20%26%3D%5Cmathbf%7B%28K'VK%29%7D%5E%7B-1%7D-%5Cmathbf%7B(K'VK)%7D%5E%7B-1%7D%20%5Cmathbf%7B(K'X)%7D%5Cleft(%5Cmathbf%7B(K'X)%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B(K'VK)%7D%5E%7B-1%7D%20%5Cmathbf%7B(K'X)%7D%5Cright)%5E%7B-%7D%20%5Cmathbf%7B(K'X)%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7B(K'VK)%7D%5E%7B-1%7D%20%5C%5C%0A%26%3D%5Cmathbf%7B(K'VK)%7D%5E%7B-1%7D%20%5Cquad%20%5Cbecause%20%5Cmathbf%7BK'X%3D0%7D%0A%5Cend%7Baligned%7D%0A" /></p><p>因此ML 的 EM 算法2式子中的 <img src="https://math.now.sh?inline=%5Cmathbf%7BZ_%7Bi%7D%5E%7B%5Cprime%7DPy%20%3D%20Z_%7Bi%7D%5E%7B%5Cprime%7DK%28K'VK%29%5E%7B-1%7DK'y%20%7D" style="display:inline-block;margin: 0;"/> ，因此其在 REML 的算法中仍为 <img src="https://math.now.sh?inline=%5Cmathbf%7BZ_%7Bi%7D%5E%7B%5Cprime%7DPy%7D" style="display:inline-block;margin: 0;"/>  不变。</p>
<p>因此，我们得到 REML 的 EM 算法步骤如下：</p>
<p><strong>step 0</strong>:  给定一组初始 <img src="https://math.now.sh?inline=%5Cmathbf%7B%5Csigma%7D%5E%7B2%280%29%7D" style="display:inline-block;margin: 0;"/> ，<img src="https://math.now.sh?inline=m%3D0" style="display:inline-block;margin: 0;"/>  。</p>
<p><strong>step 1 (E 步)</strong>: 计算 <img src="https://math.now.sh?inline=%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D" style="display:inline-block;margin: 0;"/> 的条件期望，标记为 <img src="https://math.now.sh?inline=t_%7Bi%7D" style="display:inline-block;margin: 0;"/> 。</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Chat%7Bt%7D_%7Bi%7D%5E%7B%28m%29%7D%20%26%3D%20%5Cmathrm%7BE%7D(%5Cmathbf%7Bu%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7Bu%7D_%7Bi%7D%7C%5Cmathbf%7By%7D)%7C_%7B%5Cboldsymbol%7B%5Cbeta%7D%3D%5Cboldsymbol%7B%5Cbeta%7D%5E%7B(m)%7D%2C%20%5Cmathbf%7B%5Csigma%7D%5E%7B2%7D%3D%5Cmathbf%7B%5Csigma%7D%5E%7B2(m)%7D%7D%20%5C%5C%0A%26%3D%5Csigma_%7Bi%7D%5E%7B4(m)%7D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BP%7D%5E%7B(m)%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BP%7D%5E%7B(m)%7D%5Cmathbf%7By%7D%20%5C%5C%0A%26%20%5Cquad%20%2B%20%5Cmathrm%7Btr%7D(%5Csigma_%7Bi%7D%5E%7B2(m)%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20-%20%5Csigma_%7Bi%7D%5E%7B4(m)%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BK%7D(%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cmathbf%7BV%7D%5E%7B(m)%7D%5Cmathbf%7BK%7D)%5E%7B-1%7D%20%5Cmathbf%7BK%7D%5E%7B%5Cprime%7D%5Cmathbf%7BZ%7D_%7Bi%7D)%20%5C%5C%0A%26%3D%5Csigma_%7Bi%7D%5E%7B4(m)%7D%5Cmathbf%7By%7D%5E%7B%5Cprime%7D%5Cmathbf%7BP%7D%5E%7B(m)%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%5Cmathbf%7BP%7D%5E%7B(m)%7D%5Cmathbf%7By%7D%20%20%2B%20%5Cmathrm%7Btr%7D(%5Csigma_%7Bi%7D%5E%7B2(m)%7D%5Cmathbf%7BI%7D_%7Bq_%7Bi%7D%7D%20-%20%5Csigma_%7Bi%7D%5E%7B4(m)%7D%20%5Cmathbf%7BZ%7D_%7Bi%7D%5E%7B%5Cprime%7D%20%5Cmathbf%7BP%7D%5E%7B(m)%7D%5Cmathbf%7BZ%7D_%7Bi%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A" /></p><p><strong>step 2 (M 步)</strong>: 基于完整数据，采用最大似然法，得到</p>
<p style=""><img src="https://math.now.sh?from=%5Csigma_%7Bi%7D%5E%7B2%28m%2B1%29%7D%20%3D%20%5Chat%7Bt%7D_%7Bi%7D%5E%7B(m)%7D%2Fq_%7Bi%7D%2C%20%5Cquad%20i%3D0%2C1%2C2%2C%5Ccdots%2Cr%0A" /></p><p><strong>step 3</strong>: 如果达到了收敛标准，则将 <img src="https://math.now.sh?inline=%5Cboldsymbol%7B%5Chat%7B%5Csigma%7D%7D%5E%7B2%7D%20%3D%20%5Cboldsymbol%7B%5Csigma%7D%5E%7B2%28m%2B1%29%7D" style="display:inline-block;margin: 0;"/> ；不然 m 递增1，返回 step 1 。</p>
<p>我们可以看到 REML 的 EM 算法与 ML 的 EM 算法只有一点不同，就是将公式中的 <img src="https://math.now.sh?inline=%5Cmathbf%7BV%7D%5E%7B-1%7D" style="display:inline-block;margin: 0;"/> 替换成了 <img src="https://math.now.sh?inline=%5Cmathbf%7BP%7D" style="display:inline-block;margin: 0;"/> 。</p>
<h1>参考文献</h1>
<ol>
<li>Rencher A C, Schaalje G B. Linear models in statistics[M]. John Wiley &amp; Sons, 2008.</li>
<li>Patterson H D, Thompson R. Recovery of inter-block information when block sizes are unequal[J]. Biometrika, 1971, 58(3): 545-554.</li>
<li>Hofer A. Variance component estimation in animal breeding: a review[J]. Journal of Animal Breeding and Genetics, 1998, 115(1‐6): 247-265.</li>
<li>Misztal I. Reliable computing in estimation of variance components[J]. Journal of animal breeding and genetics, 2008, 125(6): 363-370.</li>
<li>张沅, 张勤, 家畜育种. 畜禽育种中的线性模型[M]. 北京农业大学出版社, 1993.</li>
<li>Searle S R. Large sample variances of maximum likelihood estimators of variance components using unbalanced data[J]. Biometrics, 1970: 505-524.</li>
<li>Searle S R. Notes on variance components estimation-A detailed account of maximum likelihood and kindred methodology[J]. Technical Report BU-673-M, 1979.</li>
<li>Searle S R. An overview of variance component estimation[J]. Metrika, 1995, 42(1): 215-230.</li>
<li>Searle S R, Casella G, McCulloch C E. Variance components[M]. John Wiley &amp; Sons, 2009.</li>
<li>Matsaglia G, PH Styan G. Equalities and inequalities for ranks of matrices[J]. Linear and multilinear Algebra, 1974, 2(3): 269-292.</li>
<li>Marsaglia G, Styan G P H. Rank conditions for generalized inverses of partitioned matrices[J]. Sankhyā: The Indian Journal of Statistics, Series A, 1974: 437-442.</li>
<li>Bard, Y. (1974). Nonlinear Parameter Estimation. Academic Press, New York.</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/REML/" rel="tag">REML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%96%B9%E5%B7%AE%E7%BB%84%E5%88%86/" rel="tag">方差组分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/" rel="tag">理论学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" rel="tag">线性模型</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/posts/e0661366/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            方差组分估计方法三之DF-REML
          
        </div>
      </a>
    
    
      <a href="/posts/372fb709/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">方差组分估计方法一之一般思路</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "yHN3kf7fHt5wvleM2DVoHLdY-gzGzoHsz",
    app_key: "RPIwmdftljIzOtAULwc7JCAp",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "靓仔，看完留个评论再走哇！\n只需要填入昵称和邮箱就可以了",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2019-2023
        <i class="ri-heart-fill heart_icon"></i> Vincere Zhou
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>

    <!-- 与只只在一起天数 -->
	<ul>
		<li><span id="lovetime_span"></span></li>
	</ul>
    <script type="text/javascript">			
        function show_runtime() {
            window.setTimeout("show_runtime()", 1000);
            X = new Date("03/04/2021 22:11:00");
            Y = new Date();
            T = (Y.getTime() - X.getTime());
            M = 24 * 60 * 60 * 1000;
            a = T / M;
            A = Math.floor(a);
            b = (a - A) * 24;
            B = Math.floor(b);
            c = (b - B) * 60;
            C = Math.floor((b - B) * 60);
            D = Math.floor((c - C) * 60);
            lovetime_span.innerHTML = "只只和男朋友在一起了 " + A + "天" + B + "小时" + C + "分" + D + "秒"
        }
        show_runtime();
    </script>

  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/mojie.jpg" alt=""></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯茶吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/weixinpay.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300,"hOffset":80,"vOffset":-70},"mobile":{"show":false,"scale":0.5},"log":false});</script></body>

</html>